{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orDDM0ZOvp-n"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import regularizers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
        "X_train_full = X_train_full / 255.\n",
        "X_test = X_test / 255.\n",
        "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\n",
        "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]\n",
        "\n",
        "X_train = X_train[..., np.newaxis]\n",
        "X_valid = X_valid[..., np.newaxis]\n",
        "X_test = X_test[..., np.newaxis]"
      ],
      "metadata": {
        "id": "m2K_rUG3wWw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(32, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "    keras.layers.Conv2D(64, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "    keras.layers.MaxPool2D(),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dropout(0.25),\n",
        "    keras.layers.Dense(128, activation=\"relu\"),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n",
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGMxp7JhwYxG",
        "outputId": "07eda946-7e93-49f5-8ad3-9242b6fb55f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-01-23 15:23:19.452617: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-01-23 15:23:19.600725: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-01-23 15:23:19.600760: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-01-23 15:23:19.602573: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-01-23 15:23:19.602608: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-01-23 15:23:19.602622: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-01-23 15:23:19.756205: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-01-23 15:23:19.756276: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-01-23 15:23:19.756286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
            "2025-01-23 15:23:19.756321: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-01-23 15:23:19.756346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-01-23 15:23:20.951342: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
            "2025-01-23 15:23:22.217529: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f2a099e3bd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2025-01-23 15:23:22.217578: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Laptop GPU, Compute Capability 8.9\n",
            "2025-01-23 15:23:22.228483: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2025-01-23 15:23:22.317098: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1719/1719 [==============================] - 11s 5ms/step - loss: 0.1970 - accuracy: 0.9407 - val_loss: 0.0556 - val_accuracy: 0.9850\n",
            "Epoch 2/10\n",
            "1719/1719 [==============================] - 12s 7ms/step - loss: 0.0792 - accuracy: 0.9759 - val_loss: 0.0461 - val_accuracy: 0.9864\n",
            "Epoch 3/10\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0582 - accuracy: 0.9826 - val_loss: 0.0386 - val_accuracy: 0.9892\n",
            "Epoch 4/10\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.0484 - accuracy: 0.9848 - val_loss: 0.0359 - val_accuracy: 0.9900\n",
            "Epoch 5/10\n",
            "1719/1719 [==============================] - 11s 7ms/step - loss: 0.0412 - accuracy: 0.9871 - val_loss: 0.0326 - val_accuracy: 0.9918\n",
            "Epoch 6/10\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0339 - accuracy: 0.9896 - val_loss: 0.0386 - val_accuracy: 0.9900\n",
            "Epoch 7/10\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0317 - accuracy: 0.9895 - val_loss: 0.0308 - val_accuracy: 0.9928\n",
            "Epoch 8/10\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0254 - accuracy: 0.9917 - val_loss: 0.0347 - val_accuracy: 0.9924\n",
            "Epoch 9/10\n",
            "1719/1719 [==============================] - 11s 7ms/step - loss: 0.0252 - accuracy: 0.9918 - val_loss: 0.0380 - val_accuracy: 0.9926\n",
            "Epoch 10/10\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0227 - accuracy: 0.9924 - val_loss: 0.0343 - val_accuracy: 0.9924\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0266 - accuracy: 0.9924\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.02656823769211769, 0.9923999905586243]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "e_Z9l7jjwq1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"digit-recognizer/train.csv\")\n",
        "test = pd.read_csv(\"digit-recognizer/test.csv\")"
      ],
      "metadata": {
        "id": "WKYXa6D7ynj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'label' column contains target variable\n",
        "y_train_full = train['label'].values\n",
        "X_train_full = train.drop('label', axis=1).values\n",
        "\n",
        "# Split into training and validation sets\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_train_full, y_train_full, test_size=5000, random_state=42\n",
        ")\n",
        "\n",
        "# Load test data\n",
        "test = pd.read_csv(\"digit-recognizer/test.csv\")\n",
        "X_test = test.values\n",
        "\n",
        "# Normalize and reshape\n",
        "X_train_full = X_train_full / 255.\n",
        "X_test = X_test / 255.\n",
        "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\n",
        "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]\n",
        "\n",
        "X_train = X_train[..., np.newaxis]\n",
        "X_valid = X_valid[..., np.newaxis]\n",
        "X_test = X_test[..., np.newaxis]"
      ],
      "metadata": {
        "id": "rDJ_H8dwy2nS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_full = train['label'].values\n",
        "X_train_full = train.drop('label', axis=1).values\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_train_full, y_train_full, test_size=5000, random_state=42\n",
        ")\n",
        "\n",
        "test = pd.read_csv(\"digit-recognizer/test.csv\")\n",
        "X_test = test.values\n",
        "\n",
        "X_train_full = X_train_full / 255.\n",
        "X_test = X_test / 255.\n",
        "\n",
        "X_train_full = X_train_full.reshape(-1, 28, 28, 1)\n",
        "X_test = X_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_train_full, y_train_full, test_size=5000, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "nuLcs7eb-Cql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(-1, 28, 28, 1)  # Reshape to (samples, height, width, channels)\n",
        "X_valid = X_valid.reshape(-1, 28, 28, 1)\n",
        "X_test = X_test.reshape(-1, 28, 28, 1)"
      ],
      "metadata": {
        "id": "wH-CTpe09oqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(32, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "    keras.layers.Conv2D(64, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "    keras.layers.MaxPool2D(),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dropout(0.25),\n",
        "    keras.layers.Dense(128, activation=\"relu\"),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n",
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "id": "1HWYYth7zPAP",
        "outputId": "0aafade9-bb50-4e7a-e42c-b7f0d24a4af9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1157/1157 [==============================] - 8s 6ms/step - loss: 0.2206 - accuracy: 0.9328 - val_loss: 0.0680 - val_accuracy: 0.9776\n",
            "Epoch 2/10\n",
            "1157/1157 [==============================] - 7s 6ms/step - loss: 0.0877 - accuracy: 0.9734 - val_loss: 0.0491 - val_accuracy: 0.9842\n",
            "Epoch 3/10\n",
            "1157/1157 [==============================] - 7s 6ms/step - loss: 0.0656 - accuracy: 0.9803 - val_loss: 0.0417 - val_accuracy: 0.9870\n",
            "Epoch 4/10\n",
            "1157/1157 [==============================] - 9s 8ms/step - loss: 0.0531 - accuracy: 0.9836 - val_loss: 0.0474 - val_accuracy: 0.9860\n",
            "Epoch 5/10\n",
            "1157/1157 [==============================] - 7s 6ms/step - loss: 0.0447 - accuracy: 0.9856 - val_loss: 0.0464 - val_accuracy: 0.9872\n",
            "Epoch 6/10\n",
            "1157/1157 [==============================] - 7s 6ms/step - loss: 0.0378 - accuracy: 0.9878 - val_loss: 0.0407 - val_accuracy: 0.9894\n",
            "Epoch 7/10\n",
            "1157/1157 [==============================] - 7s 6ms/step - loss: 0.0347 - accuracy: 0.9887 - val_loss: 0.0443 - val_accuracy: 0.9898\n",
            "Epoch 8/10\n",
            "1157/1157 [==============================] - 7s 6ms/step - loss: 0.0287 - accuracy: 0.9907 - val_loss: 0.0441 - val_accuracy: 0.9896\n",
            "Epoch 9/10\n",
            "1157/1157 [==============================] - 9s 8ms/step - loss: 0.0266 - accuracy: 0.9913 - val_loss: 0.0467 - val_accuracy: 0.9878\n",
            "Epoch 10/10\n",
            "1157/1157 [==============================] - 7s 6ms/step - loss: 0.0238 - accuracy: 0.9922 - val_loss: 0.0478 - val_accuracy: 0.9892\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Data cardinality is ambiguous:\n  x sizes: 28000\n  y sizes: 10000\nMake sure all arrays contain the same number of samples.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[20], line 19\u001b[0m\n\u001b[1;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnadam\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     18\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(X_valid, y_valid))\n\u001b[0;32m---> 19\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/keras/src/engine/data_adapter.py:1960\u001b[0m, in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1953\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m sizes: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1954\u001b[0m         label,\n\u001b[1;32m   1955\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m   1956\u001b[0m             \u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(single_data)\n\u001b[1;32m   1957\u001b[0m         ),\n\u001b[1;32m   1958\u001b[0m     )\n\u001b[1;32m   1959\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure all arrays contain the same number of samples.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1960\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
            "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 28000\n  y sizes: 10000\nMake sure all arrays contain the same number of samples."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "train = pd.read_csv(\"digit-recognizer/train.csv\")\n",
        "\n",
        "y_train_full = train['label'].values\n",
        "X_train_full = train.drop('label', axis=1).values\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_train_full, y_train_full, test_size=5000, random_state=42\n",
        ")\n",
        "\n",
        "test = pd.read_csv(\"digit-recognizer/test.csv\")\n",
        "X_test = test.values\n",
        "\n",
        "X_train_full = X_train_full / 255.\n",
        "X_test = X_test / 255.\n",
        "\n",
        "X_train_full = X_train_full.reshape(-1, 28, 28, 1)\n",
        "X_test = X_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_train_full, y_train_full, test_size=5000, random_state=42\n",
        ")\n",
        "\n",
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(32, kernel_size=3, padding=\"same\", activation=\"relu\", input_shape=(28, 28, 1)),\n",
        "    keras.layers.Conv2D(64, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "    keras.layers.MaxPool2D(),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dropout(0.25),\n",
        "    keras.layers.Dense(128, activation=\"relu\"),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "submission_df = pd.DataFrame({'ImageId': range(1, len(predicted_labels) + 1), 'Label': predicted_labels})\n",
        "\n",
        "submission_df.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYngzDIb9hYA",
        "outputId": "6af7b334-47af-4da2-81d7-42d7f88b3d75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1157/1157 [==============================] - 8s 6ms/step - loss: 0.2384 - accuracy: 0.9255 - val_loss: 0.0750 - val_accuracy: 0.9774\n",
            "Epoch 2/10\n",
            "1157/1157 [==============================] - 7s 6ms/step - loss: 0.0925 - accuracy: 0.9724 - val_loss: 0.0478 - val_accuracy: 0.9860\n",
            "Epoch 3/10\n",
            "1157/1157 [==============================] - 7s 6ms/step - loss: 0.0669 - accuracy: 0.9797 - val_loss: 0.0435 - val_accuracy: 0.9852\n",
            "Epoch 4/10\n",
            "1157/1157 [==============================] - 9s 8ms/step - loss: 0.0542 - accuracy: 0.9830 - val_loss: 0.0431 - val_accuracy: 0.9882\n",
            "Epoch 5/10\n",
            "1157/1157 [==============================] - 7s 6ms/step - loss: 0.0470 - accuracy: 0.9852 - val_loss: 0.0403 - val_accuracy: 0.9870\n",
            "Epoch 6/10\n",
            "1157/1157 [==============================] - 7s 6ms/step - loss: 0.0381 - accuracy: 0.9875 - val_loss: 0.0403 - val_accuracy: 0.9890\n",
            "Epoch 7/10\n",
            "1157/1157 [==============================] - 7s 6ms/step - loss: 0.0373 - accuracy: 0.9887 - val_loss: 0.0392 - val_accuracy: 0.9892\n",
            "Epoch 8/10\n",
            "1157/1157 [==============================] - 9s 8ms/step - loss: 0.0307 - accuracy: 0.9903 - val_loss: 0.0396 - val_accuracy: 0.9892\n",
            "Epoch 9/10\n",
            "1157/1157 [==============================] - 7s 6ms/step - loss: 0.0247 - accuracy: 0.9924 - val_loss: 0.0485 - val_accuracy: 0.9878\n",
            "Epoch 10/10\n",
            "1157/1157 [==============================] - 7s 6ms/step - loss: 0.0257 - accuracy: 0.9918 - val_loss: 0.0445 - val_accuracy: 0.9890\n",
            "875/875 [==============================] - 1s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "train = pd.read_csv(\"digit-recognizer/train.csv\")\n",
        "y_train_full = train['label'].values\n",
        "X_train_full = train.drop('label', axis=1).values\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_train_full, y_train_full, test_size=5000, random_state=42\n",
        ")\n",
        "\n",
        "test = pd.read_csv(\"digit-recognizer/test.csv\")\n",
        "X_test = test.values\n",
        "\n",
        "X_train_full = X_train_full / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "X_train_full = X_train_full.reshape(-1, 28, 28, 1)\n",
        "X_test = X_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_train_full, y_train_full, test_size=5000, random_state=42\n",
        ")\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=False\n",
        ")\n",
        "datagen.fit(X_train)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(32, kernel_size=3, padding=\"same\", activation=\"relu\", input_shape=(28, 28, 1)),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(64, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D(),\n",
        "    keras.layers.Conv2D(128, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(128, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D(),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dropout(0.25),\n",
        "    keras.layers.Dense(256, activation=\"relu\", kernel_regularizer=regularizers.l2(0.001)),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "history = model.fit(\n",
        "    datagen.flow(X_train, y_train, batch_size=32),\n",
        "    epochs=20,\n",
        "    validation_data=(X_valid, y_valid)\n",
        ")\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "submission_df = pd.DataFrame({'ImageId': range(1, len(predicted_labels) + 1), 'Label': predicted_labels})\n",
        "submission_df.to_csv('submission2.csv', index=False)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHCZN9GS-x5r",
        "outputId": "3b257635-f7c0-4ed6-fca6-1e93e9eb35f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1157/1157 [==============================] - 11s 7ms/step - loss: 0.6406 - accuracy: 0.9232 - val_loss: 0.3196 - val_accuracy: 0.9796\n",
            "Epoch 2/20\n",
            "1157/1157 [==============================] - 8s 7ms/step - loss: 0.3381 - accuracy: 0.9632 - val_loss: 0.2708 - val_accuracy: 0.9868\n",
            "Epoch 3/20\n",
            "1157/1157 [==============================] - 8s 7ms/step - loss: 0.3091 - accuracy: 0.9692 - val_loss: 0.2695 - val_accuracy: 0.9864\n",
            "Epoch 4/20\n",
            "1157/1157 [==============================] - 11s 10ms/step - loss: 0.2937 - accuracy: 0.9729 - val_loss: 0.2505 - val_accuracy: 0.9878\n",
            "Epoch 5/20\n",
            "1157/1157 [==============================] - 8s 7ms/step - loss: 0.2936 - accuracy: 0.9743 - val_loss: 0.2581 - val_accuracy: 0.9840\n",
            "Epoch 6/20\n",
            "1157/1157 [==============================] - 8s 7ms/step - loss: 0.2841 - accuracy: 0.9761 - val_loss: 0.2157 - val_accuracy: 0.9900\n",
            "Epoch 7/20\n",
            "1157/1157 [==============================] - 8s 7ms/step - loss: 0.2673 - accuracy: 0.9769 - val_loss: 0.2585 - val_accuracy: 0.9834\n",
            "Epoch 8/20\n",
            "1157/1157 [==============================] - 11s 10ms/step - loss: 0.2606 - accuracy: 0.9790 - val_loss: 0.2220 - val_accuracy: 0.9852\n",
            "Epoch 9/20\n",
            "1157/1157 [==============================] - 8s 7ms/step - loss: 0.2601 - accuracy: 0.9787 - val_loss: 0.2220 - val_accuracy: 0.9908\n",
            "Epoch 10/20\n",
            "1157/1157 [==============================] - 8s 7ms/step - loss: 0.2587 - accuracy: 0.9792 - val_loss: 0.2195 - val_accuracy: 0.9878\n",
            "Epoch 11/20\n",
            "1157/1157 [==============================] - 8s 7ms/step - loss: 0.2409 - accuracy: 0.9812 - val_loss: 0.1925 - val_accuracy: 0.9920\n",
            "Epoch 12/20\n",
            "1157/1157 [==============================] - 11s 10ms/step - loss: 0.2241 - accuracy: 0.9825 - val_loss: 0.1958 - val_accuracy: 0.9906\n",
            "Epoch 13/20\n",
            "1157/1157 [==============================] - 8s 7ms/step - loss: 0.2310 - accuracy: 0.9818 - val_loss: 0.1948 - val_accuracy: 0.9888\n",
            "Epoch 14/20\n",
            "1157/1157 [==============================] - 8s 7ms/step - loss: 0.2119 - accuracy: 0.9841 - val_loss: 0.2064 - val_accuracy: 0.9916\n",
            "Epoch 15/20\n",
            "1157/1157 [==============================] - 8s 7ms/step - loss: 0.2196 - accuracy: 0.9836 - val_loss: 0.2051 - val_accuracy: 0.9900\n",
            "Epoch 16/20\n",
            "1157/1157 [==============================] - 11s 9ms/step - loss: 0.2118 - accuracy: 0.9843 - val_loss: 0.1738 - val_accuracy: 0.9912\n",
            "Epoch 17/20\n",
            "1157/1157 [==============================] - 8s 7ms/step - loss: 0.2081 - accuracy: 0.9842 - val_loss: 0.1834 - val_accuracy: 0.9884\n",
            "Epoch 18/20\n",
            "1157/1157 [==============================] - 8s 7ms/step - loss: 0.2048 - accuracy: 0.9854 - val_loss: 0.1987 - val_accuracy: 0.9890\n",
            "Epoch 19/20\n",
            "1157/1157 [==============================] - 8s 7ms/step - loss: 0.1993 - accuracy: 0.9858 - val_loss: 0.1805 - val_accuracy: 0.9914\n",
            "Epoch 20/20\n",
            "1157/1157 [==============================] - 11s 10ms/step - loss: 0.2028 - accuracy: 0.9845 - val_loss: 0.1866 - val_accuracy: 0.9898\n",
            "875/875 [==============================] - 1s 2ms/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 28, 28, 32)        320       \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 28, 28, 32)        128       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 28, 28, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 28, 28, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 14, 14, 64)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 14, 14, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 14, 14, 128)       512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 14, 14, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 14, 14, 128)       512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 7, 7, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6272)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 6272)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               1605888   \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 256)               1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1851146 (7.06 MB)\n",
            "Trainable params: 1849930 (7.06 MB)\n",
            "Non-trainable params: 1216 (4.75 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# THis is so COOL!!! training multiple models and combining result to create the ultimate"
      ],
      "metadata": {
        "id": "gSBRU6MSH0bR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "train = pd.read_csv(\"digit-recognizer/train.csv\")\n",
        "y_train_full = train['label'].values\n",
        "X_train_full = train.drop('label', axis=1).values\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_train_full, y_train_full, test_size=5000, random_state=42\n",
        ")\n",
        "\n",
        "test = pd.read_csv(\"digit-recognizer/test.csv\")\n",
        "X_test = test.values\n",
        "\n",
        "X_train_full = X_train_full / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "X_train_full = X_train_full.reshape(-1, 28, 28, 1)\n",
        "X_test = X_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_train_full, y_train_full, test_size=5000, random_state=42\n",
        ")\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=False\n",
        ")\n",
        "datagen.fit(X_train)\n",
        "\n",
        "def create_model():\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Conv2D(32, kernel_size=3, padding=\"same\", activation=\"relu\", input_shape=(28, 28, 1)),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Conv2D(64, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.MaxPool2D(),\n",
        "        keras.layers.Conv2D(128, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Conv2D(128, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.MaxPool2D(),\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dropout(0.25),\n",
        "        keras.layers.Dense(256, activation=\"relu\", kernel_regularizer=regularizers.l2(0.001)),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
        "\n",
        "models = [create_model() for _ in range(5)]\n",
        "for i, model in enumerate(models):\n",
        "    print(f\"Training Model {i+1}\")\n",
        "    model.fit(\n",
        "        datagen.flow(X_train, y_train, batch_size=128),\n",
        "        epochs=20, batch_size=128,\n",
        "        validation_data=(X_valid, y_valid),\n",
        "        callbacks=[reduce_lr]\n",
        "    )\n",
        "\n",
        "tta_steps = 5\n",
        "predictions = np.zeros((X_test.shape[0], 10))\n",
        "for model in models:\n",
        "    for _ in range(tta_steps):\n",
        "        predictions += model.predict(datagen.flow(X_test, batch_size=32, shuffle=False))\n",
        "predicted_labels = np.argmax(predictions / (len(models) * tta_steps), axis=1)\n",
        "\n",
        "submission_df = pd.DataFrame({'ImageId': range(1, len(predicted_labels) + 1), 'Label': predicted_labels})\n",
        "submission_df.to_csv('submission3.csv', index=False)\n",
        "\n",
        "for i, model in enumerate(models):\n",
        "    print(f\"Model {i+1} Summary\")\n",
        "    model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GOPmpvwEVin",
        "outputId": "75246b22-8d1f-4c58-ddae-7d1d38bfd4e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Model 1\n",
            "Epoch 1/20\n",
            "290/290 [==============================] - 10s 25ms/step - loss: 0.7217 - accuracy: 0.9177 - val_loss: 8.1160 - val_accuracy: 0.0978 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.3575 - accuracy: 0.9710 - val_loss: 0.2761 - val_accuracy: 0.9772 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "290/290 [==============================] - 4s 13ms/step - loss: 0.2449 - accuracy: 0.9769 - val_loss: 0.1783 - val_accuracy: 0.9864 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "290/290 [==============================] - 4s 13ms/step - loss: 0.1929 - accuracy: 0.9791 - val_loss: 0.1578 - val_accuracy: 0.9886 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "290/290 [==============================] - 4s 13ms/step - loss: 0.1760 - accuracy: 0.9815 - val_loss: 0.1630 - val_accuracy: 0.9878 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "290/290 [==============================] - 4s 13ms/step - loss: 0.1815 - accuracy: 0.9815 - val_loss: 0.1555 - val_accuracy: 0.9886 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "290/290 [==============================] - 4s 13ms/step - loss: 0.1752 - accuracy: 0.9834 - val_loss: 0.1400 - val_accuracy: 0.9920 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "290/290 [==============================] - 4s 13ms/step - loss: 0.1710 - accuracy: 0.9833 - val_loss: 0.1655 - val_accuracy: 0.9824 - lr: 0.0010\n",
            "Epoch 9/20\n",
            "290/290 [==============================] - 7s 25ms/step - loss: 0.1632 - accuracy: 0.9848 - val_loss: 0.1581 - val_accuracy: 0.9876 - lr: 0.0010\n",
            "Epoch 10/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.1602 - accuracy: 0.9848 - val_loss: 0.2000 - val_accuracy: 0.9736 - lr: 0.0010\n",
            "Epoch 11/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.1384 - accuracy: 0.9881 - val_loss: 0.1031 - val_accuracy: 0.9942 - lr: 2.0000e-04\n",
            "Epoch 12/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.1017 - accuracy: 0.9918 - val_loss: 0.0825 - val_accuracy: 0.9942 - lr: 2.0000e-04\n",
            "Epoch 13/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.0821 - accuracy: 0.9928 - val_loss: 0.0702 - val_accuracy: 0.9950 - lr: 2.0000e-04\n",
            "Epoch 14/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.0699 - accuracy: 0.9934 - val_loss: 0.0671 - val_accuracy: 0.9942 - lr: 2.0000e-04\n",
            "Epoch 15/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.0713 - accuracy: 0.9925 - val_loss: 0.0667 - val_accuracy: 0.9942 - lr: 2.0000e-04\n",
            "Epoch 16/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.0673 - accuracy: 0.9925 - val_loss: 0.0596 - val_accuracy: 0.9946 - lr: 2.0000e-04\n",
            "Epoch 17/20\n",
            "290/290 [==============================] - 7s 23ms/step - loss: 0.0614 - accuracy: 0.9932 - val_loss: 0.0544 - val_accuracy: 0.9944 - lr: 2.0000e-04\n",
            "Epoch 18/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.0590 - accuracy: 0.9934 - val_loss: 0.0539 - val_accuracy: 0.9944 - lr: 2.0000e-04\n",
            "Epoch 19/20\n",
            "290/290 [==============================] - 4s 13ms/step - loss: 0.0583 - accuracy: 0.9938 - val_loss: 0.0568 - val_accuracy: 0.9934 - lr: 2.0000e-04\n",
            "Epoch 20/20\n",
            "290/290 [==============================] - 4s 13ms/step - loss: 0.0593 - accuracy: 0.9930 - val_loss: 0.0536 - val_accuracy: 0.9952 - lr: 2.0000e-04\n",
            "Training Model 2\n",
            "Epoch 1/20\n",
            "290/290 [==============================] - 6s 14ms/step - loss: 0.7209 - accuracy: 0.9181 - val_loss: 6.1224 - val_accuracy: 0.1088 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.3667 - accuracy: 0.9702 - val_loss: 0.2899 - val_accuracy: 0.9722 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.2536 - accuracy: 0.9752 - val_loss: 0.1834 - val_accuracy: 0.9864 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.1977 - accuracy: 0.9787 - val_loss: 0.1700 - val_accuracy: 0.9822 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "290/290 [==============================] - 7s 23ms/step - loss: 0.2368 - accuracy: 0.9729 - val_loss: 0.2475 - val_accuracy: 0.9650 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "290/290 [==============================] - 4s 13ms/step - loss: 0.2041 - accuracy: 0.9786 - val_loss: 0.2130 - val_accuracy: 0.9840 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "290/290 [==============================] - 4s 13ms/step - loss: 0.1895 - accuracy: 0.9816 - val_loss: 0.1463 - val_accuracy: 0.9916 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "290/290 [==============================] - 4s 13ms/step - loss: 0.1670 - accuracy: 0.9844 - val_loss: 0.1502 - val_accuracy: 0.9884 - lr: 0.0010\n",
            "Epoch 9/20\n",
            "290/290 [==============================] - 4s 13ms/step - loss: 0.2412 - accuracy: 0.9758 - val_loss: 0.1994 - val_accuracy: 0.9858 - lr: 0.0010\n",
            "Epoch 10/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.2006 - accuracy: 0.9818 - val_loss: 0.1610 - val_accuracy: 0.9906 - lr: 0.0010\n",
            "Epoch 11/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.1502 - accuracy: 0.9877 - val_loss: 0.1181 - val_accuracy: 0.9936 - lr: 2.0000e-04\n",
            "Epoch 12/20\n",
            "290/290 [==============================] - 4s 13ms/step - loss: 0.1160 - accuracy: 0.9903 - val_loss: 0.0972 - val_accuracy: 0.9936 - lr: 2.0000e-04\n",
            "Epoch 13/20\n",
            "290/290 [==============================] - 7s 23ms/step - loss: 0.0987 - accuracy: 0.9909 - val_loss: 0.0894 - val_accuracy: 0.9924 - lr: 2.0000e-04\n",
            "Epoch 14/20\n",
            "290/290 [==============================] - 4s 13ms/step - loss: 0.0970 - accuracy: 0.9905 - val_loss: 0.0832 - val_accuracy: 0.9930 - lr: 2.0000e-04\n",
            "Epoch 15/20\n",
            "290/290 [==============================] - 4s 13ms/step - loss: 0.0848 - accuracy: 0.9916 - val_loss: 0.0741 - val_accuracy: 0.9936 - lr: 2.0000e-04\n",
            "Epoch 16/20\n",
            "290/290 [==============================] - 4s 13ms/step - loss: 0.0792 - accuracy: 0.9916 - val_loss: 0.0710 - val_accuracy: 0.9936 - lr: 2.0000e-04\n",
            "Epoch 17/20\n",
            "290/290 [==============================] - 4s 13ms/step - loss: 0.0782 - accuracy: 0.9909 - val_loss: 0.0689 - val_accuracy: 0.9938 - lr: 2.0000e-04\n",
            "Epoch 18/20\n",
            "290/290 [==============================] - 4s 13ms/step - loss: 0.0707 - accuracy: 0.9925 - val_loss: 0.0674 - val_accuracy: 0.9930 - lr: 2.0000e-04\n",
            "Epoch 19/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.0684 - accuracy: 0.9924 - val_loss: 0.0636 - val_accuracy: 0.9934 - lr: 2.0000e-04\n",
            "Epoch 20/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.0665 - accuracy: 0.9924 - val_loss: 0.0623 - val_accuracy: 0.9950 - lr: 2.0000e-04\n",
            "Training Model 3\n",
            "Epoch 1/20\n",
            "290/290 [==============================] - 9s 24ms/step - loss: 0.7286 - accuracy: 0.9189 - val_loss: 4.2960 - val_accuracy: 0.1260 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.3665 - accuracy: 0.9701 - val_loss: 0.3795 - val_accuracy: 0.9406 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.2431 - accuracy: 0.9765 - val_loss: 0.1768 - val_accuracy: 0.9860 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "290/290 [==============================] - 4s 13ms/step - loss: 0.1957 - accuracy: 0.9781 - val_loss: 0.2570 - val_accuracy: 0.9676 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.2071 - accuracy: 0.9782 - val_loss: 0.1792 - val_accuracy: 0.9864 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.1837 - accuracy: 0.9815 - val_loss: 0.1610 - val_accuracy: 0.9846 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.1677 - accuracy: 0.9832 - val_loss: 0.1340 - val_accuracy: 0.9936 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "290/290 [==============================] - 4s 13ms/step - loss: 0.1624 - accuracy: 0.9837 - val_loss: 0.2472 - val_accuracy: 0.9658 - lr: 0.0010\n",
            "Epoch 9/20\n",
            "290/290 [==============================] - 7s 23ms/step - loss: 0.1841 - accuracy: 0.9833 - val_loss: 0.1455 - val_accuracy: 0.9896 - lr: 0.0010\n",
            "Epoch 10/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.1544 - accuracy: 0.9857 - val_loss: 0.1411 - val_accuracy: 0.9872 - lr: 0.0010\n",
            "Epoch 11/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.1191 - accuracy: 0.9905 - val_loss: 0.1005 - val_accuracy: 0.9924 - lr: 2.0000e-04\n",
            "Epoch 12/20\n",
            "290/290 [==============================] - 4s 13ms/step - loss: 0.0937 - accuracy: 0.9917 - val_loss: 0.0778 - val_accuracy: 0.9946 - lr: 2.0000e-04\n",
            "Epoch 13/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.0785 - accuracy: 0.9928 - val_loss: 0.0702 - val_accuracy: 0.9924 - lr: 2.0000e-04\n",
            "Epoch 14/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.0731 - accuracy: 0.9923 - val_loss: 0.0666 - val_accuracy: 0.9936 - lr: 2.0000e-04\n",
            "Epoch 15/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.0704 - accuracy: 0.9926 - val_loss: 0.0645 - val_accuracy: 0.9934 - lr: 2.0000e-04\n",
            "Epoch 16/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.0648 - accuracy: 0.9934 - val_loss: 0.0618 - val_accuracy: 0.9928 - lr: 2.0000e-04\n",
            "Epoch 17/20\n",
            "290/290 [==============================] - 7s 23ms/step - loss: 0.0639 - accuracy: 0.9925 - val_loss: 0.0613 - val_accuracy: 0.9934 - lr: 2.0000e-04\n",
            "Epoch 18/20\n",
            "290/290 [==============================] - 4s 13ms/step - loss: 0.0604 - accuracy: 0.9935 - val_loss: 0.0544 - val_accuracy: 0.9948 - lr: 2.0000e-04\n",
            "Epoch 19/20\n",
            "290/290 [==============================] - 4s 13ms/step - loss: 0.0559 - accuracy: 0.9941 - val_loss: 0.0545 - val_accuracy: 0.9936 - lr: 2.0000e-04\n",
            "Epoch 20/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.0573 - accuracy: 0.9931 - val_loss: 0.0555 - val_accuracy: 0.9946 - lr: 2.0000e-04\n",
            "Training Model 4\n",
            "Epoch 1/20\n",
            "290/290 [==============================] - 6s 15ms/step - loss: 0.7327 - accuracy: 0.9168 - val_loss: 3.3825 - val_accuracy: 0.1820 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.3738 - accuracy: 0.9696 - val_loss: 0.2765 - val_accuracy: 0.9822 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "290/290 [==============================] - 4s 13ms/step - loss: 0.2482 - accuracy: 0.9759 - val_loss: 0.1834 - val_accuracy: 0.9856 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.1988 - accuracy: 0.9791 - val_loss: 0.1484 - val_accuracy: 0.9878 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "290/290 [==============================] - 7s 24ms/step - loss: 0.1697 - accuracy: 0.9818 - val_loss: 0.1513 - val_accuracy: 0.9860 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.1706 - accuracy: 0.9809 - val_loss: 0.1697 - val_accuracy: 0.9806 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.1656 - accuracy: 0.9825 - val_loss: 0.1416 - val_accuracy: 0.9876 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.1566 - accuracy: 0.9852 - val_loss: 0.1773 - val_accuracy: 0.9780 - lr: 0.0010\n",
            "Epoch 9/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.1546 - accuracy: 0.9845 - val_loss: 0.1284 - val_accuracy: 0.9920 - lr: 0.0010\n",
            "Epoch 10/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.1612 - accuracy: 0.9847 - val_loss: 0.1683 - val_accuracy: 0.9864 - lr: 0.0010\n",
            "Epoch 11/20\n",
            "290/290 [==============================] - 4s 13ms/step - loss: 0.1596 - accuracy: 0.9851 - val_loss: 0.1473 - val_accuracy: 0.9884 - lr: 0.0010\n",
            "Epoch 12/20\n",
            "290/290 [==============================] - 4s 13ms/step - loss: 0.1595 - accuracy: 0.9858 - val_loss: 0.1531 - val_accuracy: 0.9880 - lr: 0.0010\n",
            "Epoch 13/20\n",
            "290/290 [==============================] - 7s 23ms/step - loss: 0.1262 - accuracy: 0.9907 - val_loss: 0.0977 - val_accuracy: 0.9932 - lr: 2.0000e-04\n",
            "Epoch 14/20\n",
            "290/290 [==============================] - 4s 13ms/step - loss: 0.0944 - accuracy: 0.9932 - val_loss: 0.0775 - val_accuracy: 0.9940 - lr: 2.0000e-04\n",
            "Epoch 15/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.0734 - accuracy: 0.9942 - val_loss: 0.0672 - val_accuracy: 0.9946 - lr: 2.0000e-04\n",
            "Epoch 16/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.0665 - accuracy: 0.9937 - val_loss: 0.0625 - val_accuracy: 0.9942 - lr: 2.0000e-04\n",
            "Epoch 17/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.0629 - accuracy: 0.9934 - val_loss: 0.0579 - val_accuracy: 0.9948 - lr: 2.0000e-04\n",
            "Epoch 18/20\n",
            "290/290 [==============================] - 4s 13ms/step - loss: 0.0594 - accuracy: 0.9939 - val_loss: 0.0537 - val_accuracy: 0.9944 - lr: 2.0000e-04\n",
            "Epoch 19/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.0580 - accuracy: 0.9932 - val_loss: 0.0567 - val_accuracy: 0.9926 - lr: 2.0000e-04\n",
            "Epoch 20/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.0537 - accuracy: 0.9948 - val_loss: 0.0514 - val_accuracy: 0.9934 - lr: 2.0000e-04\n",
            "Training Model 5\n",
            "Epoch 1/20\n",
            "290/290 [==============================] - 8s 24ms/step - loss: 0.7170 - accuracy: 0.9186 - val_loss: 3.4631 - val_accuracy: 0.2388 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "290/290 [==============================] - 4s 13ms/step - loss: 0.3721 - accuracy: 0.9688 - val_loss: 0.3340 - val_accuracy: 0.9630 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.2469 - accuracy: 0.9756 - val_loss: 0.2732 - val_accuracy: 0.9694 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "290/290 [==============================] - 4s 13ms/step - loss: 0.2165 - accuracy: 0.9780 - val_loss: 0.1597 - val_accuracy: 0.9876 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "290/290 [==============================] - 4s 13ms/step - loss: 0.1832 - accuracy: 0.9808 - val_loss: 0.1510 - val_accuracy: 0.9872 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "290/290 [==============================] - 4s 13ms/step - loss: 0.1805 - accuracy: 0.9802 - val_loss: 0.1550 - val_accuracy: 0.9870 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "290/290 [==============================] - 4s 13ms/step - loss: 0.1639 - accuracy: 0.9835 - val_loss: 0.1415 - val_accuracy: 0.9904 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "290/290 [==============================] - 4s 13ms/step - loss: 0.1828 - accuracy: 0.9815 - val_loss: 0.1830 - val_accuracy: 0.9848 - lr: 0.0010\n",
            "Epoch 9/20\n",
            "290/290 [==============================] - 7s 23ms/step - loss: 0.1697 - accuracy: 0.9851 - val_loss: 0.1612 - val_accuracy: 0.9842 - lr: 0.0010\n",
            "Epoch 10/20\n",
            "290/290 [==============================] - 4s 13ms/step - loss: 0.1665 - accuracy: 0.9848 - val_loss: 0.1828 - val_accuracy: 0.9844 - lr: 0.0010\n",
            "Epoch 11/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.1467 - accuracy: 0.9894 - val_loss: 0.1123 - val_accuracy: 0.9948 - lr: 2.0000e-04\n",
            "Epoch 12/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.1084 - accuracy: 0.9919 - val_loss: 0.0867 - val_accuracy: 0.9938 - lr: 2.0000e-04\n",
            "Epoch 13/20\n",
            "290/290 [==============================] - 4s 13ms/step - loss: 0.0867 - accuracy: 0.9925 - val_loss: 0.0781 - val_accuracy: 0.9930 - lr: 2.0000e-04\n",
            "Epoch 14/20\n",
            "290/290 [==============================] - 4s 13ms/step - loss: 0.0765 - accuracy: 0.9929 - val_loss: 0.0659 - val_accuracy: 0.9942 - lr: 2.0000e-04\n",
            "Epoch 15/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.0684 - accuracy: 0.9930 - val_loss: 0.0604 - val_accuracy: 0.9926 - lr: 2.0000e-04\n",
            "Epoch 16/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.0606 - accuracy: 0.9939 - val_loss: 0.0575 - val_accuracy: 0.9944 - lr: 2.0000e-04\n",
            "Epoch 17/20\n",
            "290/290 [==============================] - 7s 23ms/step - loss: 0.0630 - accuracy: 0.9925 - val_loss: 0.0594 - val_accuracy: 0.9932 - lr: 2.0000e-04\n",
            "Epoch 18/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.0602 - accuracy: 0.9932 - val_loss: 0.0571 - val_accuracy: 0.9942 - lr: 2.0000e-04\n",
            "Epoch 19/20\n",
            "290/290 [==============================] - 4s 13ms/step - loss: 0.0591 - accuracy: 0.9933 - val_loss: 0.0558 - val_accuracy: 0.9940 - lr: 2.0000e-04\n",
            "Epoch 20/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.0543 - accuracy: 0.9940 - val_loss: 0.0561 - val_accuracy: 0.9930 - lr: 2.0000e-04\n",
            "875/875 [==============================] - 4s 4ms/step\n",
            "875/875 [==============================] - 4s 4ms/step\n",
            "875/875 [==============================] - 4s 5ms/step\n",
            "875/875 [==============================] - 4s 4ms/step\n",
            "875/875 [==============================] - 7s 8ms/step\n",
            "875/875 [==============================] - 4s 4ms/step\n",
            "875/875 [==============================] - 4s 4ms/step\n",
            "875/875 [==============================] - 4s 4ms/step\n",
            "875/875 [==============================] - 4s 4ms/step\n",
            "875/875 [==============================] - 4s 4ms/step\n",
            "875/875 [==============================] - 4s 4ms/step\n",
            "875/875 [==============================] - 4s 4ms/step\n",
            "875/875 [==============================] - 7s 8ms/step\n",
            "875/875 [==============================] - 4s 5ms/step\n",
            "875/875 [==============================] - 4s 4ms/step\n",
            "875/875 [==============================] - 4s 4ms/step\n",
            "875/875 [==============================] - 4s 4ms/step\n",
            "875/875 [==============================] - 4s 4ms/step\n",
            "875/875 [==============================] - 4s 5ms/step\n",
            "875/875 [==============================] - 7s 8ms/step\n",
            "875/875 [==============================] - 4s 4ms/step\n",
            "875/875 [==============================] - 4s 4ms/step\n",
            "875/875 [==============================] - 4s 4ms/step\n",
            "875/875 [==============================] - 4s 4ms/step\n",
            "875/875 [==============================] - 4s 4ms/step\n",
            "Model 1 Summary\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 28, 28, 32)        320       \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 28, 28, 32)        128       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 28, 28, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 28, 28, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 14, 14, 64)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 14, 14, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 14, 14, 128)       512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 14, 14, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 14, 14, 128)       512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 7, 7, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6272)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 6272)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               1605888   \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 256)               1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1851146 (7.06 MB)\n",
            "Trainable params: 1849930 (7.06 MB)\n",
            "Non-trainable params: 1216 (4.75 KB)\n",
            "_________________________________________________________________\n",
            "Model 2 Summary\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 28, 28, 32)        320       \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 28, 28, 32)        128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 28, 28, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_6 (Bat  (None, 28, 28, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 14, 14, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 14, 14, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_7 (Bat  (None, 14, 14, 128)       512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 14, 14, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_8 (Bat  (None, 14, 14, 128)       512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 7, 7, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 6272)              0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 6272)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               1605888   \n",
            "                                                                 \n",
            " batch_normalization_9 (Bat  (None, 256)               1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1851146 (7.06 MB)\n",
            "Trainable params: 1849930 (7.06 MB)\n",
            "Non-trainable params: 1216 (4.75 KB)\n",
            "_________________________________________________________________\n",
            "Model 3 Summary\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_8 (Conv2D)           (None, 28, 28, 32)        320       \n",
            "                                                                 \n",
            " batch_normalization_10 (Ba  (None, 28, 28, 32)        128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 28, 28, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_11 (Ba  (None, 28, 28, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 14, 14, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 14, 14, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_12 (Ba  (None, 14, 14, 128)       512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 14, 14, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_13 (Ba  (None, 14, 14, 128)       512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 7, 7, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 6272)              0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 6272)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 256)               1605888   \n",
            "                                                                 \n",
            " batch_normalization_14 (Ba  (None, 256)               1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1851146 (7.06 MB)\n",
            "Trainable params: 1849930 (7.06 MB)\n",
            "Non-trainable params: 1216 (4.75 KB)\n",
            "_________________________________________________________________\n",
            "Model 4 Summary\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_12 (Conv2D)          (None, 28, 28, 32)        320       \n",
            "                                                                 \n",
            " batch_normalization_15 (Ba  (None, 28, 28, 32)        128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 28, 28, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_16 (Ba  (None, 28, 28, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPoolin  (None, 14, 14, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 14, 14, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_17 (Ba  (None, 14, 14, 128)       512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 14, 14, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_18 (Ba  (None, 14, 14, 128)       512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 7, 7, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 6272)              0         \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 6272)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 256)               1605888   \n",
            "                                                                 \n",
            " batch_normalization_19 (Ba  (None, 256)               1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1851146 (7.06 MB)\n",
            "Trainable params: 1849930 (7.06 MB)\n",
            "Non-trainable params: 1216 (4.75 KB)\n",
            "_________________________________________________________________\n",
            "Model 5 Summary\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_16 (Conv2D)          (None, 28, 28, 32)        320       \n",
            "                                                                 \n",
            " batch_normalization_20 (Ba  (None, 28, 28, 32)        128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 28, 28, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_21 (Ba  (None, 28, 28, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPoolin  (None, 14, 14, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 14, 14, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_22 (Ba  (None, 14, 14, 128)       512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 14, 14, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_23 (Ba  (None, 14, 14, 128)       512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPoolin  (None, 7, 7, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 6272)              0         \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 6272)              0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 256)               1605888   \n",
            "                                                                 \n",
            " batch_normalization_24 (Ba  (None, 256)               1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1851146 (7.06 MB)\n",
            "Trainable params: 1849930 (7.06 MB)\n",
            "Non-trainable params: 1216 (4.75 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['TF_ENABLE_LAYOUT_OPTIMIZER'] = '0'  # Disable layout optimizer\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "\n",
        "# Enable mixed precision (optional)\n",
        "from tensorflow.keras.mixed_precision import set_global_policy\n",
        "set_global_policy('mixed_float16')\n",
        "\n",
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "train = pd.read_csv(\"digit-recognizer/train.csv\")\n",
        "y_train_full = train['label'].values\n",
        "X_train_full = train.drop('label', axis=1).values\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_train_full, y_train_full, test_size=5000, random_state=42\n",
        ")\n",
        "\n",
        "test = pd.read_csv(\"digit-recognizer/test.csv\")\n",
        "X_test = test.values\n",
        "\n",
        "X_train_full = X_train_full / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "X_train_full = X_train_full.reshape(-1, 28, 28, 1)\n",
        "X_test = X_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_train_full, y_train_full, test_size=5000, random_state=42\n",
        ")\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=False\n",
        ")\n",
        "datagen.fit(X_train)\n",
        "\n",
        "def create_cnn_model():\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Conv2D(32, kernel_size=3, padding=\"same\", activation=\"relu\", input_shape=(28, 28, 1)),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Conv2D(64, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.MaxPool2D(),\n",
        "        keras.layers.Conv2D(128, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Conv2D(128, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.MaxPool2D(),\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dropout(0.25),\n",
        "        keras.layers.Dense(256, activation=\"relu\", kernel_regularizer=regularizers.l2(0.001)),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "def create_efficientnet_model():\n",
        "    inputs = keras.Input(shape=(28, 28, 1))\n",
        "    resized_inputs = keras.layers.Resizing(32, 32)(inputs)  # Resize to 32x32\n",
        "    base_model = EfficientNetB0(weights=None, include_top=False, input_shape=(32, 32, 1))\n",
        "    base_model.trainable = True\n",
        "    x = base_model(resized_inputs)\n",
        "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    x = keras.layers.Dropout(0.5)(x)\n",
        "    outputs = keras.layers.Dense(10, activation=\"softmax\")(x)\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
        "\n",
        "models = [create_cnn_model() for _ in range(3)] + [create_efficientnet_model() for _ in range(2)]\n",
        "for i, model in enumerate(models):\n",
        "    print(f\"Training Model {i+1}\")\n",
        "    model.fit(\n",
        "        datagen.flow(X_train, y_train, batch_size=128),  # Reduced batch size\n",
        "        epochs=20,\n",
        "        validation_data=(X_valid, y_valid),\n",
        "        callbacks=[reduce_lr]\n",
        "    )\n",
        "\n",
        "tta_steps = 10\n",
        "predictions = np.zeros((X_test.shape[0], 10))\n",
        "for model in models:\n",
        "    for _ in range(tta_steps):\n",
        "        predictions += model.predict(datagen.flow(X_test, batch_size=128, shuffle=False))\n",
        "predicted_labels = np.argmax(predictions / (len(models) * tta_steps), axis=1)\n",
        "\n",
        "submission_df = pd.DataFrame({'ImageId': range(1, len(predicted_labels) + 1), 'Label': predicted_labels})\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "\n",
        "for i, model in enumerate(models):\n",
        "    print(f\"Model {i+1} Summary\")\n",
        "    model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KI16SddzF4cC",
        "outputId": "b3b512eb-9817-4c87-edef-ac9c6262c400"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
            "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 4060 Laptop GPU, compute capability 8.9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-01-23 17:39:19.167121: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Model 1\n",
            "Epoch 1/20\n",
            "290/290 [==============================] - 8s 19ms/step - loss: 0.7535 - accuracy: 0.9103 - val_loss: 2.9868 - val_accuracy: 0.3700 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "290/290 [==============================] - 4s 15ms/step - loss: 0.3721 - accuracy: 0.9703 - val_loss: 0.3251 - val_accuracy: 0.9634 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.2459 - accuracy: 0.9775 - val_loss: 0.2282 - val_accuracy: 0.9774 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "290/290 [==============================] - 7s 26ms/step - loss: 0.1974 - accuracy: 0.9794 - val_loss: 0.1585 - val_accuracy: 0.9874 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "290/290 [==============================] - 4s 15ms/step - loss: 0.1897 - accuracy: 0.9794 - val_loss: 0.1883 - val_accuracy: 0.9850 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "290/290 [==============================] - 4s 15ms/step - loss: 0.1880 - accuracy: 0.9808 - val_loss: 0.2801 - val_accuracy: 0.9718 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.1942 - accuracy: 0.9821 - val_loss: 0.1527 - val_accuracy: 0.9894 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "290/290 [==============================] - 4s 15ms/step - loss: 0.1675 - accuracy: 0.9839 - val_loss: 0.1497 - val_accuracy: 0.9890 - lr: 0.0010\n",
            "Epoch 9/20\n",
            "290/290 [==============================] - 4s 15ms/step - loss: 0.1574 - accuracy: 0.9853 - val_loss: 0.1320 - val_accuracy: 0.9912 - lr: 0.0010\n",
            "Epoch 10/20\n",
            "290/290 [==============================] - 4s 15ms/step - loss: 0.1704 - accuracy: 0.9840 - val_loss: 0.1513 - val_accuracy: 0.9888 - lr: 0.0010\n",
            "Epoch 11/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.1781 - accuracy: 0.9845 - val_loss: 0.1513 - val_accuracy: 0.9894 - lr: 0.0010\n",
            "Epoch 12/20\n",
            "290/290 [==============================] - 8s 26ms/step - loss: 0.1593 - accuracy: 0.9861 - val_loss: 0.1459 - val_accuracy: 0.9888 - lr: 0.0010\n",
            "Epoch 13/20\n",
            "290/290 [==============================] - 4s 15ms/step - loss: 0.1227 - accuracy: 0.9913 - val_loss: 0.0980 - val_accuracy: 0.9944 - lr: 2.0000e-04\n",
            "Epoch 14/20\n",
            "290/290 [==============================] - 4s 15ms/step - loss: 0.0936 - accuracy: 0.9931 - val_loss: 0.0825 - val_accuracy: 0.9930 - lr: 2.0000e-04\n",
            "Epoch 15/20\n",
            "290/290 [==============================] - 4s 15ms/step - loss: 0.0763 - accuracy: 0.9935 - val_loss: 0.0679 - val_accuracy: 0.9934 - lr: 2.0000e-04\n",
            "Epoch 16/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.0664 - accuracy: 0.9935 - val_loss: 0.0600 - val_accuracy: 0.9938 - lr: 2.0000e-04\n",
            "Epoch 17/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.0587 - accuracy: 0.9943 - val_loss: 0.0587 - val_accuracy: 0.9932 - lr: 2.0000e-04\n",
            "Epoch 18/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.0582 - accuracy: 0.9936 - val_loss: 0.0623 - val_accuracy: 0.9926 - lr: 2.0000e-04\n",
            "Epoch 19/20\n",
            "290/290 [==============================] - 4s 15ms/step - loss: 0.0553 - accuracy: 0.9938 - val_loss: 0.0540 - val_accuracy: 0.9940 - lr: 2.0000e-04\n",
            "Epoch 20/20\n",
            "290/290 [==============================] - 7s 25ms/step - loss: 0.0537 - accuracy: 0.9939 - val_loss: 0.0536 - val_accuracy: 0.9938 - lr: 2.0000e-04\n",
            "Training Model 2\n",
            "Epoch 1/20\n",
            "290/290 [==============================] - 6s 17ms/step - loss: 0.7634 - accuracy: 0.9085 - val_loss: 5.4330 - val_accuracy: 0.1646 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.3838 - accuracy: 0.9702 - val_loss: 0.2883 - val_accuracy: 0.9782 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.2886 - accuracy: 0.9724 - val_loss: 0.1934 - val_accuracy: 0.9902 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.2037 - accuracy: 0.9796 - val_loss: 0.1750 - val_accuracy: 0.9818 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "290/290 [==============================] - 4s 15ms/step - loss: 0.1854 - accuracy: 0.9797 - val_loss: 0.1509 - val_accuracy: 0.9892 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "290/290 [==============================] - 4s 15ms/step - loss: 0.2069 - accuracy: 0.9772 - val_loss: 0.2053 - val_accuracy: 0.9860 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "290/290 [==============================] - 8s 27ms/step - loss: 0.1953 - accuracy: 0.9816 - val_loss: 0.1707 - val_accuracy: 0.9854 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "290/290 [==============================] - 4s 15ms/step - loss: 0.1682 - accuracy: 0.9834 - val_loss: 0.1445 - val_accuracy: 0.9900 - lr: 0.0010\n",
            "Epoch 9/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.1623 - accuracy: 0.9845 - val_loss: 0.1521 - val_accuracy: 0.9862 - lr: 0.0010\n",
            "Epoch 10/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.1656 - accuracy: 0.9841 - val_loss: 0.1442 - val_accuracy: 0.9914 - lr: 0.0010\n",
            "Epoch 11/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.1611 - accuracy: 0.9851 - val_loss: 0.1441 - val_accuracy: 0.9896 - lr: 0.0010\n",
            "Epoch 12/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.1674 - accuracy: 0.9851 - val_loss: 0.1626 - val_accuracy: 0.9854 - lr: 0.0010\n",
            "Epoch 13/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.1580 - accuracy: 0.9860 - val_loss: 0.1408 - val_accuracy: 0.9910 - lr: 0.0010\n",
            "Epoch 14/20\n",
            "290/290 [==============================] - 7s 25ms/step - loss: 0.1852 - accuracy: 0.9843 - val_loss: 0.1500 - val_accuracy: 0.9912 - lr: 0.0010\n",
            "Epoch 15/20\n",
            "290/290 [==============================] - 4s 15ms/step - loss: 0.1564 - accuracy: 0.9868 - val_loss: 0.1529 - val_accuracy: 0.9880 - lr: 0.0010\n",
            "Epoch 16/20\n",
            "290/290 [==============================] - 4s 15ms/step - loss: 0.1521 - accuracy: 0.9874 - val_loss: 0.1356 - val_accuracy: 0.9910 - lr: 0.0010\n",
            "Epoch 17/20\n",
            "290/290 [==============================] - 4s 15ms/step - loss: 0.1526 - accuracy: 0.9865 - val_loss: 0.1559 - val_accuracy: 0.9886 - lr: 0.0010\n",
            "Epoch 18/20\n",
            "290/290 [==============================] - 4s 15ms/step - loss: 0.1536 - accuracy: 0.9874 - val_loss: 0.1430 - val_accuracy: 0.9900 - lr: 0.0010\n",
            "Epoch 19/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.1508 - accuracy: 0.9873 - val_loss: 0.1446 - val_accuracy: 0.9902 - lr: 0.0010\n",
            "Epoch 20/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.1169 - accuracy: 0.9926 - val_loss: 0.0942 - val_accuracy: 0.9936 - lr: 2.0000e-04\n",
            "Training Model 3\n",
            "Epoch 1/20\n",
            "290/290 [==============================] - 6s 17ms/step - loss: 0.7514 - accuracy: 0.9123 - val_loss: 3.5695 - val_accuracy: 0.2134 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "290/290 [==============================] - 7s 25ms/step - loss: 0.3693 - accuracy: 0.9716 - val_loss: 0.2923 - val_accuracy: 0.9736 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "290/290 [==============================] - 4s 15ms/step - loss: 0.2478 - accuracy: 0.9777 - val_loss: 0.2117 - val_accuracy: 0.9774 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.2324 - accuracy: 0.9759 - val_loss: 0.1844 - val_accuracy: 0.9886 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "290/290 [==============================] - 4s 15ms/step - loss: 0.1908 - accuracy: 0.9802 - val_loss: 0.1700 - val_accuracy: 0.9838 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "290/290 [==============================] - 4s 15ms/step - loss: 0.1727 - accuracy: 0.9816 - val_loss: 0.1356 - val_accuracy: 0.9900 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "290/290 [==============================] - 4s 15ms/step - loss: 0.1651 - accuracy: 0.9828 - val_loss: 0.1357 - val_accuracy: 0.9884 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.1608 - accuracy: 0.9837 - val_loss: 0.1560 - val_accuracy: 0.9880 - lr: 0.0010\n",
            "Epoch 9/20\n",
            "290/290 [==============================] - 7s 25ms/step - loss: 0.1689 - accuracy: 0.9843 - val_loss: 0.1595 - val_accuracy: 0.9874 - lr: 0.0010\n",
            "Epoch 10/20\n",
            "290/290 [==============================] - 4s 15ms/step - loss: 0.1373 - accuracy: 0.9897 - val_loss: 0.1061 - val_accuracy: 0.9948 - lr: 2.0000e-04\n",
            "Epoch 11/20\n",
            "290/290 [==============================] - 4s 15ms/step - loss: 0.1031 - accuracy: 0.9923 - val_loss: 0.0847 - val_accuracy: 0.9950 - lr: 2.0000e-04\n",
            "Epoch 12/20\n",
            "290/290 [==============================] - 4s 15ms/step - loss: 0.0884 - accuracy: 0.9915 - val_loss: 0.0746 - val_accuracy: 0.9950 - lr: 2.0000e-04\n",
            "Epoch 13/20\n",
            "290/290 [==============================] - 4s 15ms/step - loss: 0.0764 - accuracy: 0.9923 - val_loss: 0.0659 - val_accuracy: 0.9944 - lr: 2.0000e-04\n",
            "Epoch 14/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.0675 - accuracy: 0.9928 - val_loss: 0.0626 - val_accuracy: 0.9936 - lr: 2.0000e-04\n",
            "Epoch 15/20\n",
            "290/290 [==============================] - 4s 15ms/step - loss: 0.0663 - accuracy: 0.9928 - val_loss: 0.0611 - val_accuracy: 0.9944 - lr: 2.0000e-04\n",
            "Epoch 16/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.0644 - accuracy: 0.9927 - val_loss: 0.0585 - val_accuracy: 0.9944 - lr: 2.0000e-04\n",
            "Epoch 17/20\n",
            "290/290 [==============================] - 7s 25ms/step - loss: 0.0609 - accuracy: 0.9932 - val_loss: 0.0580 - val_accuracy: 0.9926 - lr: 2.0000e-04\n",
            "Epoch 18/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.0572 - accuracy: 0.9936 - val_loss: 0.0593 - val_accuracy: 0.9928 - lr: 2.0000e-04\n",
            "Epoch 19/20\n",
            "290/290 [==============================] - 4s 15ms/step - loss: 0.0586 - accuracy: 0.9928 - val_loss: 0.0555 - val_accuracy: 0.9938 - lr: 2.0000e-04\n",
            "Epoch 20/20\n",
            "290/290 [==============================] - 4s 14ms/step - loss: 0.0564 - accuracy: 0.9935 - val_loss: 0.0566 - val_accuracy: 0.9950 - lr: 2.0000e-04\n",
            "Training Model 4\n",
            "Epoch 1/20\n",
            "290/290 [==============================] - 42s 94ms/step - loss: 2.0002 - accuracy: 0.3521 - val_loss: 2.4760 - val_accuracy: 0.0978 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "290/290 [==============================] - 23s 80ms/step - loss: 0.7192 - accuracy: 0.7654 - val_loss: 3.9288 - val_accuracy: 0.1222 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "290/290 [==============================] - 20s 68ms/step - loss: 0.3557 - accuracy: 0.8902 - val_loss: 0.2145 - val_accuracy: 0.9290 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "290/290 [==============================] - 23s 80ms/step - loss: 0.2538 - accuracy: 0.9226 - val_loss: 0.2250 - val_accuracy: 0.9410 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "290/290 [==============================] - 23s 79ms/step - loss: 0.2065 - accuracy: 0.9404 - val_loss: 0.1403 - val_accuracy: 0.9552 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "290/290 [==============================] - 20s 69ms/step - loss: 0.1743 - accuracy: 0.9475 - val_loss: 0.0797 - val_accuracy: 0.9738 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "290/290 [==============================] - 23s 79ms/step - loss: 0.1350 - accuracy: 0.9598 - val_loss: 0.5920 - val_accuracy: 0.8046 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "290/290 [==============================] - 23s 79ms/step - loss: 0.2069 - accuracy: 0.9385 - val_loss: 0.1319 - val_accuracy: 0.9604 - lr: 0.0010\n",
            "Epoch 9/20\n",
            "290/290 [==============================] - 20s 69ms/step - loss: 0.1325 - accuracy: 0.9613 - val_loss: 0.0988 - val_accuracy: 0.9688 - lr: 0.0010\n",
            "Epoch 10/20\n",
            "290/290 [==============================] - 23s 79ms/step - loss: 0.0915 - accuracy: 0.9729 - val_loss: 0.0528 - val_accuracy: 0.9830 - lr: 2.0000e-04\n",
            "Epoch 11/20\n",
            "290/290 [==============================] - 20s 69ms/step - loss: 0.0886 - accuracy: 0.9730 - val_loss: 0.0523 - val_accuracy: 0.9816 - lr: 2.0000e-04\n",
            "Epoch 12/20\n",
            "290/290 [==============================] - 23s 78ms/step - loss: 0.0859 - accuracy: 0.9731 - val_loss: 0.0413 - val_accuracy: 0.9868 - lr: 2.0000e-04\n",
            "Epoch 13/20\n",
            "290/290 [==============================] - 23s 79ms/step - loss: 0.0754 - accuracy: 0.9774 - val_loss: 0.0418 - val_accuracy: 0.9864 - lr: 2.0000e-04\n",
            "Epoch 14/20\n",
            "290/290 [==============================] - 20s 69ms/step - loss: 0.0821 - accuracy: 0.9752 - val_loss: 0.0504 - val_accuracy: 0.9832 - lr: 2.0000e-04\n",
            "Epoch 15/20\n",
            "290/290 [==============================] - 23s 79ms/step - loss: 0.0741 - accuracy: 0.9773 - val_loss: 0.0342 - val_accuracy: 0.9882 - lr: 2.0000e-04\n",
            "Epoch 16/20\n",
            "290/290 [==============================] - 23s 79ms/step - loss: 0.0737 - accuracy: 0.9779 - val_loss: 0.0396 - val_accuracy: 0.9866 - lr: 2.0000e-04\n",
            "Epoch 17/20\n",
            "290/290 [==============================] - 20s 68ms/step - loss: 0.0735 - accuracy: 0.9783 - val_loss: 0.0664 - val_accuracy: 0.9800 - lr: 2.0000e-04\n",
            "Epoch 18/20\n",
            "290/290 [==============================] - 23s 78ms/step - loss: 0.0679 - accuracy: 0.9793 - val_loss: 0.0510 - val_accuracy: 0.9852 - lr: 2.0000e-04\n",
            "Epoch 19/20\n",
            "290/290 [==============================] - 20s 68ms/step - loss: 0.0643 - accuracy: 0.9807 - val_loss: 0.0338 - val_accuracy: 0.9894 - lr: 4.0000e-05\n",
            "Epoch 20/20\n",
            "290/290 [==============================] - 23s 79ms/step - loss: 0.0581 - accuracy: 0.9822 - val_loss: 0.0343 - val_accuracy: 0.9892 - lr: 4.0000e-05\n",
            "Training Model 5\n",
            "Epoch 1/20\n",
            "290/290 [==============================] - 39s 88ms/step - loss: 2.0157 - accuracy: 0.3604 - val_loss: 2.3741 - val_accuracy: 0.0978 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "290/290 [==============================] - 23s 78ms/step - loss: 0.7496 - accuracy: 0.7571 - val_loss: 2.3222 - val_accuracy: 0.2062 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "290/290 [==============================] - 19s 67ms/step - loss: 0.3783 - accuracy: 0.8838 - val_loss: 0.1626 - val_accuracy: 0.9472 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "290/290 [==============================] - 23s 78ms/step - loss: 0.2512 - accuracy: 0.9228 - val_loss: 0.1827 - val_accuracy: 0.9470 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "290/290 [==============================] - 19s 67ms/step - loss: 0.2052 - accuracy: 0.9387 - val_loss: 0.0966 - val_accuracy: 0.9726 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "290/290 [==============================] - 23s 80ms/step - loss: 0.1909 - accuracy: 0.9426 - val_loss: 0.1119 - val_accuracy: 0.9668 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "290/290 [==============================] - 22s 77ms/step - loss: 0.1587 - accuracy: 0.9535 - val_loss: 0.1044 - val_accuracy: 0.9684 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "290/290 [==============================] - 19s 66ms/step - loss: 0.1330 - accuracy: 0.9596 - val_loss: 0.1078 - val_accuracy: 0.9674 - lr: 0.0010\n",
            "Epoch 9/20\n",
            "290/290 [==============================] - 23s 81ms/step - loss: 0.1002 - accuracy: 0.9700 - val_loss: 0.0583 - val_accuracy: 0.9842 - lr: 2.0000e-04\n",
            "Epoch 10/20\n",
            "290/290 [==============================] - 22s 75ms/step - loss: 0.0911 - accuracy: 0.9726 - val_loss: 0.0521 - val_accuracy: 0.9856 - lr: 2.0000e-04\n",
            "Epoch 11/20\n",
            "290/290 [==============================] - 19s 67ms/step - loss: 0.0890 - accuracy: 0.9733 - val_loss: 0.0760 - val_accuracy: 0.9776 - lr: 2.0000e-04\n",
            "Epoch 12/20\n",
            "290/290 [==============================] - 24s 81ms/step - loss: 0.0879 - accuracy: 0.9736 - val_loss: 0.0494 - val_accuracy: 0.9864 - lr: 2.0000e-04\n",
            "Epoch 13/20\n",
            "290/290 [==============================] - 19s 67ms/step - loss: 0.0855 - accuracy: 0.9748 - val_loss: 0.0525 - val_accuracy: 0.9846 - lr: 2.0000e-04\n",
            "Epoch 14/20\n",
            "290/290 [==============================] - 22s 76ms/step - loss: 0.0787 - accuracy: 0.9756 - val_loss: 0.1589 - val_accuracy: 0.9438 - lr: 2.0000e-04\n",
            "Epoch 15/20\n",
            "290/290 [==============================] - 23s 80ms/step - loss: 0.0842 - accuracy: 0.9748 - val_loss: 0.0572 - val_accuracy: 0.9838 - lr: 2.0000e-04\n",
            "Epoch 16/20\n",
            "290/290 [==============================] - 19s 67ms/step - loss: 0.0708 - accuracy: 0.9791 - val_loss: 0.0446 - val_accuracy: 0.9870 - lr: 4.0000e-05\n",
            "Epoch 17/20\n",
            "290/290 [==============================] - 23s 78ms/step - loss: 0.0654 - accuracy: 0.9800 - val_loss: 0.0428 - val_accuracy: 0.9868 - lr: 4.0000e-05\n",
            "Epoch 18/20\n",
            "290/290 [==============================] - 20s 67ms/step - loss: 0.0630 - accuracy: 0.9808 - val_loss: 0.0445 - val_accuracy: 0.9868 - lr: 4.0000e-05\n",
            "Epoch 19/20\n",
            "290/290 [==============================] - 23s 79ms/step - loss: 0.0653 - accuracy: 0.9807 - val_loss: 0.0422 - val_accuracy: 0.9864 - lr: 4.0000e-05\n",
            "Epoch 20/20\n",
            "290/290 [==============================] - 23s 79ms/step - loss: 0.0640 - accuracy: 0.9802 - val_loss: 0.0439 - val_accuracy: 0.9868 - lr: 4.0000e-05\n",
            "219/219 [==============================] - 3s 13ms/step\n",
            "219/219 [==============================] - 3s 13ms/step\n",
            "219/219 [==============================] - 3s 12ms/step\n",
            "219/219 [==============================] - 3s 12ms/step\n",
            "219/219 [==============================] - 3s 12ms/step\n",
            "219/219 [==============================] - 3s 12ms/step\n",
            "219/219 [==============================] - 3s 12ms/step\n",
            "219/219 [==============================] - 3s 12ms/step\n",
            "219/219 [==============================] - 6s 28ms/step\n",
            "219/219 [==============================] - 3s 13ms/step\n",
            "219/219 [==============================] - 3s 13ms/step\n",
            "219/219 [==============================] - 3s 13ms/step\n",
            "219/219 [==============================] - 3s 13ms/step\n",
            "219/219 [==============================] - 3s 12ms/step\n",
            "219/219 [==============================] - 3s 13ms/step\n",
            "219/219 [==============================] - 3s 13ms/step\n",
            "219/219 [==============================] - 3s 12ms/step\n",
            "219/219 [==============================] - 3s 12ms/step\n",
            "219/219 [==============================] - 6s 27ms/step\n",
            "219/219 [==============================] - 3s 12ms/step\n",
            "219/219 [==============================] - 3s 13ms/step\n",
            "219/219 [==============================] - 3s 13ms/step\n",
            "219/219 [==============================] - 3s 13ms/step\n",
            "219/219 [==============================] - 3s 13ms/step\n",
            "219/219 [==============================] - 3s 13ms/step\n",
            "219/219 [==============================] - 3s 13ms/step\n",
            "219/219 [==============================] - 3s 13ms/step\n",
            "219/219 [==============================] - 3s 13ms/step\n",
            "219/219 [==============================] - 6s 26ms/step\n",
            "219/219 [==============================] - 3s 13ms/step\n",
            "219/219 [==============================] - 16s 32ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MSfcXoyuJ2Tc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}