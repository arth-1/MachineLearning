{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABvMOTUre6d7",
        "outputId": "aa29e531-da70-4ee0-f42b-93bd68ce8fff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-01-20 04:25:21.142676: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-01-20 04:25:21.185034: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-20 04:25:21.185067: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-20 04:25:21.185126: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-20 04:25:21.201285: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-01-20 04:25:21.920844: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/home/arth/.local/lib/python3.11/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
            "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n",
            "2025-01-20 04:25:25.170134: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-01-20 04:25:25.334450: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-01-20 04:25:25.334486: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-01-20 04:25:25.338631: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-01-20 04:25:25.338671: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-01-20 04:25:25.338687: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-01-20 04:25:26.163428: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-01-20 04:25:26.163504: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-01-20 04:25:26.163511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
            "2025-01-20 04:25:26.163548: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-01-20 04:25:26.163579: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
        "for _ in range(20):\n",
        "    model.add(keras.layers.Dense(100,\n",
        "                                 activation=\"elu\",\n",
        "                                 kernel_initializer=\"he_normal\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "8c0LavNyfZh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.Nadam(learning_rate=5e-5)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "_s05WI2Sf6Xj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "X_train = X_train_full[5000:]\n",
        "y_train = y_train_full[5000:]\n",
        "X_val = X_train_full[:5000]\n",
        "y_val = y_train_full[:5000]"
      ],
      "metadata": {
        "id": "HinsAfj9gCSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
        "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_model.h5\", save_best_only=True)\n",
        "run_index = 1 # increment every time you train the model\n",
        "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_{:03d}\".format(run_index))\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
        "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]"
      ],
      "metadata": {
        "id": "o3HnF9TTgoX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorboard --logdir=./my_cifar10_logs --port=6006"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BH7s_ynEhR-u",
        "outputId": "de37b5a5-fcc4-43e6-ed6f-d9f2b3b64a06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-01-18 13:07:51.947648: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-01-18 13:07:51.972173: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-18 13:07:51.972238: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-18 13:07:51.972259: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-18 13:07:51.977460: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-01-18 13:07:52.839225: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2025-01-18 13:07:54.185433: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-01-18 13:07:54.255252: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-01-18 13:07:54.255308: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "\n",
            "NOTE: Using experimental fast data loading logic. To disable, pass\n",
            "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
            "    https://github.com/tensorflow/tensorboard/issues/4784\n",
            "\n",
            "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
            "TensorBoard 2.14.1 at http://localhost:6006/ (Press CTRL+C to quit)\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=100, batch_size=256, validation_data=(X_val, y_val), callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KD4LHIQJhpji",
        "outputId": "d8be7c08-2747-4dd3-da5e-8ca7dd816d1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "176/176 [==============================] - 3s 16ms/step - loss: 1.2157 - accuracy: 0.5633 - val_loss: 1.4817 - val_accuracy: 0.4876\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 6s 32ms/step - loss: 1.1926 - accuracy: 0.5717 - val_loss: 1.4855 - val_accuracy: 0.4816\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 3s 15ms/step - loss: 1.1841 - accuracy: 0.5758 - val_loss: 1.4927 - val_accuracy: 0.4826\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 3s 15ms/step - loss: 1.1780 - accuracy: 0.5785 - val_loss: 1.4904 - val_accuracy: 0.4884\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 3s 15ms/step - loss: 1.1725 - accuracy: 0.5813 - val_loss: 1.5009 - val_accuracy: 0.4790\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 3s 15ms/step - loss: 1.1688 - accuracy: 0.5828 - val_loss: 1.5035 - val_accuracy: 0.4820\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 3s 15ms/step - loss: 1.1647 - accuracy: 0.5832 - val_loss: 1.5082 - val_accuracy: 0.4792\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 3s 15ms/step - loss: 1.1606 - accuracy: 0.5849 - val_loss: 1.5133 - val_accuracy: 0.4836\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 3s 15ms/step - loss: 1.1559 - accuracy: 0.5865 - val_loss: 1.5124 - val_accuracy: 0.4824\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 3s 15ms/step - loss: 1.1534 - accuracy: 0.5863 - val_loss: 1.5249 - val_accuracy: 0.4804\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 3s 15ms/step - loss: 1.1508 - accuracy: 0.5873 - val_loss: 1.5106 - val_accuracy: 0.4814\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 3s 15ms/step - loss: 1.1453 - accuracy: 0.5908 - val_loss: 1.5207 - val_accuracy: 0.4812\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 3s 15ms/step - loss: 1.1422 - accuracy: 0.5918 - val_loss: 1.5255 - val_accuracy: 0.4792\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 6s 32ms/step - loss: 1.1406 - accuracy: 0.5922 - val_loss: 1.5328 - val_accuracy: 0.4770\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 3s 15ms/step - loss: 1.1350 - accuracy: 0.5942 - val_loss: 1.5233 - val_accuracy: 0.4780\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 3s 16ms/step - loss: 1.1292 - accuracy: 0.5952 - val_loss: 1.5481 - val_accuracy: 0.4778\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 3s 15ms/step - loss: 1.1242 - accuracy: 0.5979 - val_loss: 1.5427 - val_accuracy: 0.4768\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 3s 16ms/step - loss: 1.1239 - accuracy: 0.5971 - val_loss: 1.5333 - val_accuracy: 0.4856\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 3s 15ms/step - loss: 1.1168 - accuracy: 0.6005 - val_loss: 1.5545 - val_accuracy: 0.4812\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 3s 15ms/step - loss: 1.1125 - accuracy: 0.6027 - val_loss: 1.5349 - val_accuracy: 0.4846\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 3s 15ms/step - loss: 1.1062 - accuracy: 0.6049 - val_loss: 1.5613 - val_accuracy: 0.4812\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f844c4fbf50>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(\"my_cifar10_model.h5\")\n",
        "model.evaluate(X_val, y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Os8uba7_iWgt",
        "outputId": "f3dc8dce-7138-44a0-9e4e-f53b71d698fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 1s 4ms/step - loss: 1.4817 - accuracy: 0.4876\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.4816808700561523, 0.4875999987125397]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
        "\n",
        "for _ in range(20):\n",
        "    model.add(keras.layers.Dense(100,\n",
        "                                 kernel_initializer=\"he_normal\"))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    model.add(keras.layers.Activation(\"elu\"))\n",
        "\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "optimizer = keras.optimizers.Nadam(learning_rate=5e-4)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
        "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_bn_model.h5\", save_best_only=True)\n",
        "run_index = 1 # increment every time you train the model\n",
        "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_bn_{:03d}\".format(run_index))\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
        "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
        "\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=256,\n",
        "          validation_data=(X_val, y_val),\n",
        "          callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGnjUMaXlb6b",
        "outputId": "1d37fed1-8378-453e-8c34-f98892637b49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "176/176 [==============================] - 17s 37ms/step - loss: 1.8190 - accuracy: 0.3519 - val_loss: 2.0792 - val_accuracy: 0.3306\n",
            "Epoch 2/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/arth/.local/lib/python3.11/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "176/176 [==============================] - 6s 36ms/step - loss: 1.5428 - accuracy: 0.4532 - val_loss: 1.9078 - val_accuracy: 0.3384\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 9s 54ms/step - loss: 1.4401 - accuracy: 0.4858 - val_loss: 1.7643 - val_accuracy: 0.3966\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 6s 37ms/step - loss: 1.3732 - accuracy: 0.5111 - val_loss: 1.6369 - val_accuracy: 0.4288\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 6s 36ms/step - loss: 1.3139 - accuracy: 0.5316 - val_loss: 1.6933 - val_accuracy: 0.4138\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 6s 36ms/step - loss: 1.2652 - accuracy: 0.5511 - val_loss: 1.9175 - val_accuracy: 0.3496\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 6s 36ms/step - loss: 1.2202 - accuracy: 0.5680 - val_loss: 1.6726 - val_accuracy: 0.4298\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 9s 53ms/step - loss: 1.1785 - accuracy: 0.5812 - val_loss: 1.6312 - val_accuracy: 0.4606\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 7s 37ms/step - loss: 1.1410 - accuracy: 0.5950 - val_loss: 1.5344 - val_accuracy: 0.4854\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 6s 37ms/step - loss: 1.1095 - accuracy: 0.6072 - val_loss: 1.5228 - val_accuracy: 0.4810\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 6s 36ms/step - loss: 1.0761 - accuracy: 0.6187 - val_loss: 1.6009 - val_accuracy: 0.4656\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 6s 36ms/step - loss: 1.0415 - accuracy: 0.6304 - val_loss: 1.8068 - val_accuracy: 0.4112\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 9s 53ms/step - loss: 1.0105 - accuracy: 0.6401 - val_loss: 1.6465 - val_accuracy: 0.4580\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 6s 36ms/step - loss: 0.9835 - accuracy: 0.6516 - val_loss: 1.6441 - val_accuracy: 0.4570\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 6s 36ms/step - loss: 0.9559 - accuracy: 0.6620 - val_loss: 1.6541 - val_accuracy: 0.4590\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 6s 36ms/step - loss: 0.9233 - accuracy: 0.6718 - val_loss: 1.6808 - val_accuracy: 0.4658\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 6s 36ms/step - loss: 0.8978 - accuracy: 0.6811 - val_loss: 1.7209 - val_accuracy: 0.4584\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 9s 52ms/step - loss: 0.8763 - accuracy: 0.6887 - val_loss: 1.6605 - val_accuracy: 0.4826\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 6s 36ms/step - loss: 0.8499 - accuracy: 0.6974 - val_loss: 1.8127 - val_accuracy: 0.4592\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 6s 36ms/step - loss: 0.8243 - accuracy: 0.7074 - val_loss: 1.9316 - val_accuracy: 0.4550\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 6s 36ms/step - loss: 0.8002 - accuracy: 0.7142 - val_loss: 1.8052 - val_accuracy: 0.4682\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 6s 36ms/step - loss: 0.7781 - accuracy: 0.7228 - val_loss: 1.8132 - val_accuracy: 0.4658\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 9s 53ms/step - loss: 0.7564 - accuracy: 0.7312 - val_loss: 1.7396 - val_accuracy: 0.4828\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 6s 36ms/step - loss: 0.7300 - accuracy: 0.7383 - val_loss: 1.9039 - val_accuracy: 0.4582\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 6s 36ms/step - loss: 0.7126 - accuracy: 0.7462 - val_loss: 1.8826 - val_accuracy: 0.4648\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 6s 36ms/step - loss: 0.7001 - accuracy: 0.7500 - val_loss: 1.8267 - val_accuracy: 0.4762\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 6s 36ms/step - loss: 0.6719 - accuracy: 0.7611 - val_loss: 1.9568 - val_accuracy: 0.4608\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 6s 36ms/step - loss: 0.6548 - accuracy: 0.7646 - val_loss: 1.9188 - val_accuracy: 0.4670\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 9s 53ms/step - loss: 0.6380 - accuracy: 0.7723 - val_loss: 1.9119 - val_accuracy: 0.4660\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 6s 36ms/step - loss: 0.6213 - accuracy: 0.7770 - val_loss: 2.0109 - val_accuracy: 0.4646\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f843423e590>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(\"my_cifar10_bn_model.h5\")\n",
        "model.evaluate(X_val, y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72iUJOh5oFRX",
        "outputId": "857e1b02-c785-4142-8b04-eaf0890a60d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 1s 6ms/step - loss: 1.5228 - accuracy: 0.4810\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.522750735282898, 0.48100000619888306]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
        "for _ in range(20):\n",
        "    model.add(keras.layers.Dense(100,\n",
        "                                 kernel_initializer=\"lecun_normal\",\n",
        "                                 activation=\"selu\"))\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "optimizer = keras.optimizers.Nadam(learning_rate=7e-4)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
        "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_selu_model.h5\", save_best_only=True)\n",
        "run_index = 1 # increment every time you train the model\n",
        "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_selu_{:03d}\".format(run_index))\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
        "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
        "\n",
        "X_means = X_train.mean(axis=0)\n",
        "X_stds = X_train.std(axis=0)\n",
        "X_train_scaled = (X_train - X_means) / X_stds\n",
        "X_valid_scaled = (X_val - X_means) / X_stds\n",
        "X_test_scaled = (X_test - X_means) / X_stds\n",
        "\n",
        "model.fit(X_train_scaled, y_train, epochs=100,\n",
        "          validation_data=(X_valid_scaled, y_val), batch_size=128,\n",
        "          callbacks=callbacks)\n",
        "\n",
        "model = keras.models.load_model(\"my_cifar10_selu_model.h5\")\n",
        "model.evaluate(X_valid_scaled, y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FB9RXJIpHFl",
        "outputId": "a76fb7a1-a6d3-4c22-8e3f-ad03f7c91179"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-01-18 14:45:07.749008: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f1edb0475b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2025-01-18 14:45:07.749055: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Laptop GPU, Compute Capability 8.9\n",
            "2025-01-18 14:45:07.766643: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2025-01-18 14:45:07.797197: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
            "2025-01-18 14:45:07.982200: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "352/352 [==============================] - 15s 19ms/step - loss: 1.8501 - accuracy: 0.3403 - val_loss: 1.7067 - val_accuracy: 0.3890\n",
            "Epoch 2/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/arth/.local/lib/python3.11/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "352/352 [==============================] - 9s 27ms/step - loss: 1.6456 - accuracy: 0.4190 - val_loss: 1.6135 - val_accuracy: 0.4238\n",
            "Epoch 3/100\n",
            "352/352 [==============================] - 6s 18ms/step - loss: 1.5359 - accuracy: 0.4549 - val_loss: 1.5694 - val_accuracy: 0.4496\n",
            "Epoch 4/100\n",
            "352/352 [==============================] - 6s 18ms/step - loss: 1.4637 - accuracy: 0.4835 - val_loss: 1.5171 - val_accuracy: 0.4594\n",
            "Epoch 5/100\n",
            "352/352 [==============================] - 7s 19ms/step - loss: 1.3958 - accuracy: 0.5103 - val_loss: 1.4723 - val_accuracy: 0.4824\n",
            "Epoch 6/100\n",
            "352/352 [==============================] - 7s 19ms/step - loss: 1.3439 - accuracy: 0.5270 - val_loss: 1.4614 - val_accuracy: 0.4782\n",
            "Epoch 7/100\n",
            "352/352 [==============================] - 9s 27ms/step - loss: 1.2984 - accuracy: 0.5414 - val_loss: 1.4560 - val_accuracy: 0.4906\n",
            "Epoch 8/100\n",
            "352/352 [==============================] - 6s 18ms/step - loss: 1.2521 - accuracy: 0.5612 - val_loss: 1.4514 - val_accuracy: 0.4932\n",
            "Epoch 9/100\n",
            "352/352 [==============================] - 6s 18ms/step - loss: 1.2139 - accuracy: 0.5741 - val_loss: 1.4424 - val_accuracy: 0.5002\n",
            "Epoch 10/100\n",
            "352/352 [==============================] - 6s 18ms/step - loss: 1.1819 - accuracy: 0.5880 - val_loss: 1.4761 - val_accuracy: 0.5090\n",
            "Epoch 11/100\n",
            "352/352 [==============================] - 6s 18ms/step - loss: 1.1415 - accuracy: 0.6024 - val_loss: 1.4318 - val_accuracy: 0.5118\n",
            "Epoch 12/100\n",
            "352/352 [==============================] - 9s 25ms/step - loss: 1.1085 - accuracy: 0.6144 - val_loss: 1.4844 - val_accuracy: 0.4962\n",
            "Epoch 13/100\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 1.0734 - accuracy: 0.6255 - val_loss: 1.4959 - val_accuracy: 0.5052\n",
            "Epoch 14/100\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 1.0420 - accuracy: 0.6383 - val_loss: 1.4645 - val_accuracy: 0.5110\n",
            "Epoch 15/100\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 1.0109 - accuracy: 0.6498 - val_loss: 1.4768 - val_accuracy: 0.5088\n",
            "Epoch 16/100\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.9815 - accuracy: 0.6599 - val_loss: 1.5038 - val_accuracy: 0.5158\n",
            "Epoch 17/100\n",
            "352/352 [==============================] - 9s 26ms/step - loss: 0.9531 - accuracy: 0.6693 - val_loss: 1.5221 - val_accuracy: 0.5170\n",
            "Epoch 18/100\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.9266 - accuracy: 0.6818 - val_loss: 1.5473 - val_accuracy: 0.5130\n",
            "Epoch 19/100\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.9059 - accuracy: 0.6883 - val_loss: 1.5998 - val_accuracy: 0.5084\n",
            "Epoch 20/100\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.8753 - accuracy: 0.6998 - val_loss: 1.5944 - val_accuracy: 0.5106\n",
            "Epoch 21/100\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.8461 - accuracy: 0.7120 - val_loss: 1.6310 - val_accuracy: 0.4984\n",
            "Epoch 22/100\n",
            "352/352 [==============================] - 9s 26ms/step - loss: 0.8289 - accuracy: 0.7162 - val_loss: 1.6880 - val_accuracy: 0.5028\n",
            "Epoch 23/100\n",
            "352/352 [==============================] - 6s 18ms/step - loss: 0.8044 - accuracy: 0.7254 - val_loss: 1.6442 - val_accuracy: 0.5076\n",
            "Epoch 24/100\n",
            "352/352 [==============================] - 6s 17ms/step - loss: 0.7827 - accuracy: 0.7326 - val_loss: 1.6564 - val_accuracy: 0.5104\n",
            "Epoch 25/100\n",
            "352/352 [==============================] - 6s 18ms/step - loss: 0.7681 - accuracy: 0.7362 - val_loss: 1.6525 - val_accuracy: 0.5118\n",
            "Epoch 26/100\n",
            "352/352 [==============================] - 6s 18ms/step - loss: 0.7422 - accuracy: 0.7470 - val_loss: 1.7692 - val_accuracy: 0.5034\n",
            "Epoch 27/100\n",
            "352/352 [==============================] - 6s 18ms/step - loss: 0.7294 - accuracy: 0.7545 - val_loss: 1.6593 - val_accuracy: 0.5084\n",
            "Epoch 28/100\n",
            "352/352 [==============================] - 9s 26ms/step - loss: 0.7036 - accuracy: 0.7624 - val_loss: 1.7305 - val_accuracy: 0.5184\n",
            "Epoch 29/100\n",
            "352/352 [==============================] - 6s 18ms/step - loss: 0.6901 - accuracy: 0.7686 - val_loss: 1.7583 - val_accuracy: 0.4950\n",
            "Epoch 30/100\n",
            "352/352 [==============================] - 6s 18ms/step - loss: 0.6704 - accuracy: 0.7747 - val_loss: 1.7977 - val_accuracy: 0.4920\n",
            "Epoch 31/100\n",
            "352/352 [==============================] - 6s 18ms/step - loss: 0.6540 - accuracy: 0.7790 - val_loss: 1.7972 - val_accuracy: 0.4980\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 1.4318 - accuracy: 0.5118\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.4317923784255981, 0.5117999911308289]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(\"my_cifar10_selu_model.h5\")\n",
        "model.evaluate(X_valid_scaled, y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoHCBicN2ZjC",
        "outputId": "974a005a-1cc5-44b6-fd61-d9a1754c68f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 1s 7ms/step - loss: 1.4318 - accuracy: 0.5118\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.4317923784255981, 0.5117999911308289]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
        "for _ in range(20):\n",
        "    model.add(keras.layers.Dense(100,\n",
        "                                 kernel_initializer=\"lecun_normal\",\n",
        "                                 activation=\"selu\"))\n",
        "\n",
        "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "optimizer = keras.optimizers.Nadam(learning_rate=5e-4)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
        "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_alpha_dropout_model.h5\", save_best_only=True)\n",
        "run_index = 1 # increment every time you train the model\n",
        "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_alpha_dropout_{:03d}\".format(run_index))\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
        "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
        "\n",
        "X_means = X_train.mean(axis=0)\n",
        "X_stds = X_train.std(axis=0)\n",
        "X_train_scaled = (X_train - X_means) / X_stds\n",
        "X_valid_scaled = (X_val - X_means) / X_stds\n",
        "X_test_scaled = (X_test - X_means) / X_stds\n",
        "\n",
        "model.fit(X_train_scaled, y_train, epochs=100,\n",
        "          validation_data=(X_valid_scaled, y_val), batch_size=256,\n",
        "          callbacks=callbacks)\n",
        "\n",
        "model = keras.models.load_model(\"my_cifar10_alpha_dropout_model.h5\")\n",
        "model.evaluate(X_valid_scaled, y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zff2bKqn47nh",
        "outputId": "465d8363-2a4b-4327-d779-bb3f17f5cbbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-01-18 15:55:11.056077: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1fb51ed0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2025-01-18 15:55:11.056244: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Laptop GPU, Compute Capability 8.9\n",
            "2025-01-18 15:55:11.076503: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2025-01-18 15:55:11.112760: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
            "2025-01-18 15:55:11.240526: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "176/176 [==============================] - 16s 40ms/step - loss: 1.9404 - accuracy: 0.3192 - val_loss: 1.6585 - val_accuracy: 0.4070\n",
            "Epoch 2/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/arth/.local/lib/python3.11/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "176/176 [==============================] - 4s 21ms/step - loss: 1.6289 - accuracy: 0.4199 - val_loss: 1.5836 - val_accuracy: 0.4444\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 4s 21ms/step - loss: 1.5090 - accuracy: 0.4634 - val_loss: 1.5299 - val_accuracy: 0.4600\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 4s 20ms/step - loss: 1.4290 - accuracy: 0.4934 - val_loss: 1.5071 - val_accuracy: 0.4768\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 3s 20ms/step - loss: 1.3661 - accuracy: 0.5168 - val_loss: 1.4664 - val_accuracy: 0.4904\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 4s 21ms/step - loss: 1.3056 - accuracy: 0.5406 - val_loss: 1.4569 - val_accuracy: 0.4952\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 3s 19ms/step - loss: 1.2622 - accuracy: 0.5534 - val_loss: 1.4882 - val_accuracy: 0.4974\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 3s 18ms/step - loss: 1.2121 - accuracy: 0.5696 - val_loss: 1.4761 - val_accuracy: 0.5074\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 3s 19ms/step - loss: 1.1671 - accuracy: 0.5878 - val_loss: 1.5484 - val_accuracy: 0.4960\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 3s 17ms/step - loss: 1.1304 - accuracy: 0.6011 - val_loss: 1.5264 - val_accuracy: 0.5060\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 6s 35ms/step - loss: 1.0943 - accuracy: 0.6140 - val_loss: 1.5322 - val_accuracy: 0.5142\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 3s 18ms/step - loss: 1.0489 - accuracy: 0.6293 - val_loss: 1.5289 - val_accuracy: 0.5132\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 3s 18ms/step - loss: 1.0166 - accuracy: 0.6391 - val_loss: 1.5912 - val_accuracy: 0.5162\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 3s 19ms/step - loss: 0.9808 - accuracy: 0.6533 - val_loss: 1.5584 - val_accuracy: 0.5148\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 3s 17ms/step - loss: 0.9458 - accuracy: 0.6644 - val_loss: 1.6161 - val_accuracy: 0.5148\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 3s 17ms/step - loss: 0.9189 - accuracy: 0.6762 - val_loss: 1.6941 - val_accuracy: 0.5120\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 3s 18ms/step - loss: 0.8873 - accuracy: 0.6874 - val_loss: 1.6536 - val_accuracy: 0.5274\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 3s 19ms/step - loss: 0.8570 - accuracy: 0.6964 - val_loss: 1.7695 - val_accuracy: 0.5072\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 3s 19ms/step - loss: 0.8302 - accuracy: 0.7066 - val_loss: 1.7993 - val_accuracy: 0.5228\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 3s 19ms/step - loss: 0.8002 - accuracy: 0.7170 - val_loss: 1.8419 - val_accuracy: 0.5090\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 6s 35ms/step - loss: 0.7714 - accuracy: 0.7279 - val_loss: 1.8717 - val_accuracy: 0.5046\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 3s 19ms/step - loss: 0.7441 - accuracy: 0.7380 - val_loss: 1.8544 - val_accuracy: 0.5098\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 3s 19ms/step - loss: 0.7275 - accuracy: 0.7439 - val_loss: 1.9537 - val_accuracy: 0.5110\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 3s 18ms/step - loss: 0.7018 - accuracy: 0.7532 - val_loss: 1.9854 - val_accuracy: 0.5070\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 3s 18ms/step - loss: 0.6741 - accuracy: 0.7612 - val_loss: 2.0514 - val_accuracy: 0.5054\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 3s 19ms/step - loss: 0.6523 - accuracy: 0.7701 - val_loss: 2.0399 - val_accuracy: 0.4936\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 1.4569 - accuracy: 0.4952\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.4569337368011475, 0.4952000081539154]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MCAlphaDropout(keras.layers.AlphaDropout):\n",
        "    def call(self, inputs):\n",
        "        return super().call(inputs, training=True)"
      ],
      "metadata": {
        "id": "kr-UPPkd7XEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mc_model = keras.models.Sequential([\n",
        "    MCAlphaDropout(layer.rate) if isinstance(layer, keras.layers.AlphaDropout) else layer\n",
        "    for layer in model.layers\n",
        "])"
      ],
      "metadata": {
        "id": "vmOOXSkm9SSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mc_dropout_predict_probas(mc_model, X, n_samples=10):\n",
        "    Y_probas = [mc_model.predict(X) for sample in range(n_samples)]\n",
        "    return np.mean(Y_probas, axis=0)\n",
        "\n",
        "def mc_dropout_predict_classes(mc_model, X, n_samples=10):\n",
        "    Y_probas = mc_dropout_predict_probas(mc_model, X, n_samples)\n",
        "    return np.argmax(Y_probas, axis=1)"
      ],
      "metadata": {
        "id": "IAJn1BSP9UeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "y_pred = mc_dropout_predict_classes(mc_model, X_valid_scaled)\n",
        "accuracy = np.mean(y_pred == y_val[:, 0])\n",
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXjrC8UC9gJz",
        "outputId": "82a5e4e1-abe9-4f1d-b10e-85cca714e546"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 1s 3ms/step\n",
            "157/157 [==============================] - 0s 2ms/step\n",
            "157/157 [==============================] - 0s 3ms/step\n",
            "157/157 [==============================] - 0s 2ms/step\n",
            "157/157 [==============================] - 0s 3ms/step\n",
            "157/157 [==============================] - 0s 2ms/step\n",
            "157/157 [==============================] - 0s 2ms/step\n",
            "157/157 [==============================] - 0s 2ms/step\n",
            "157/157 [==============================] - 0s 2ms/step\n",
            "157/157 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4954"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
        "for _ in range(20):\n",
        "    model.add(keras.layers.Dense(100,\n",
        "                                 kernel_initializer=\"lecun_normal\",\n",
        "                                 activation=\"selu\"))\n",
        "\n",
        "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "optimizer = keras.optimizers.SGD(learning_rate=1e-3)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "_oBVHIif9iWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "K = keras.backend\n",
        "\n",
        "class ExponentialLearningRate(keras.callbacks.Callback):\n",
        "    def __init__(self, factor):\n",
        "        self.factor = factor\n",
        "        self.rates = []\n",
        "        self.losses = []\n",
        "    def on_batch_end(self, batch, logs):\n",
        "        self.rates.append(K.get_value(self.model.optimizer.learning_rate))\n",
        "        self.losses.append(logs[\"loss\"])\n",
        "        K.set_value(self.model.optimizer.learning_rate, self.model.optimizer.learning_rate * self.factor)\n",
        "\n",
        "def find_learning_rate(model, X, y, epochs=1, batch_size=32, min_rate=10**-5, max_rate=10):\n",
        "    init_weights = model.get_weights()\n",
        "    iterations = math.ceil(len(X) / batch_size) * epochs\n",
        "    factor = np.exp(np.log(max_rate / min_rate) / iterations)\n",
        "    init_lr = K.get_value(model.optimizer.learning_rate)\n",
        "    K.set_value(model.optimizer.learning_rate, min_rate)\n",
        "    exp_lr = ExponentialLearningRate(factor)\n",
        "    history = model.fit(X, y, epochs=epochs, batch_size=batch_size,\n",
        "                        callbacks=[exp_lr])\n",
        "    K.set_value(model.optimizer.learning_rate, init_lr)\n",
        "    model.set_weights(init_weights)\n",
        "    return exp_lr.rates, exp_lr.losses\n",
        "\n",
        "def plot_lr_vs_loss(rates, losses):\n",
        "    plt.plot(rates, losses)\n",
        "    plt.gca().set_xscale('log')\n",
        "    plt.hlines(min(losses), min(rates), max(rates))\n",
        "    plt.axis([min(rates), max(rates), min(losses), (losses[0] + min(losses)) / 2])\n",
        "    plt.xlabel(\"Learning rate\")\n",
        "    plt.ylabel(\"Loss\")"
      ],
      "metadata": {
        "id": "uUqzkSGfFT18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "batch_size = 256\n",
        "rates, losses = find_learning_rate(model, X_train_scaled, y_train, epochs=1, batch_size=batch_size)\n",
        "plot_lr_vs_loss(rates, losses)\n",
        "plt.axis([min(rates), max(rates), min(losses), (losses[0] + min(losses)) / 1.4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "5sVjZakvErlC",
        "outputId": "7082d1d4-6236-48c9-d5be-7184a8cd1728"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "176/176 [==============================] - 7s 29ms/step - loss: nan - accuracy: 0.1353\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9.999999747378752e-06,\n",
              " 9.245111465454102,\n",
              " 2.688497543334961,\n",
              " 4.066368852342879)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
        "for _ in range(20):\n",
        "    model.add(keras.layers.Dense(100,\n",
        "                                 kernel_initializer=\"lecun_normal\",\n",
        "                                 activation=\"selu\"))\n",
        "\n",
        "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "optimizer = keras.optimizers.SGD(learning_rate=1e-2)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "pShMNbMOEvQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OneCycleScheduler(keras.callbacks.Callback):\n",
        "    def __init__(self, iterations, max_rate, start_rate=None,\n",
        "                 last_iterations=None, last_rate=None):\n",
        "        self.iterations = iterations\n",
        "        self.max_rate = max_rate\n",
        "        self.start_rate = start_rate or max_rate / 10\n",
        "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
        "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
        "        self.last_rate = last_rate or self.start_rate / 1000\n",
        "        self.iteration = 0\n",
        "    def _interpolate(self, iter1, iter2, rate1, rate2):\n",
        "        return ((rate2 - rate1) * (self.iteration - iter1)\n",
        "                / (iter2 - iter1) + rate1)\n",
        "    def on_batch_begin(self, batch, logs):\n",
        "        if self.iteration < self.half_iteration:\n",
        "            rate = self._interpolate(0, self.half_iteration, self.start_rate, self.max_rate)\n",
        "        elif self.iteration < 2 * self.half_iteration:\n",
        "            rate = self._interpolate(self.half_iteration, 2 * self.half_iteration,\n",
        "                                     self.max_rate, self.start_rate)\n",
        "        else:\n",
        "            rate = self._interpolate(2 * self.half_iteration, self.iterations,\n",
        "                                     self.start_rate, self.last_rate)\n",
        "        self.iteration += 1\n",
        "        K.set_value(self.model.optimizer.learning_rate, rate)"
      ],
      "metadata": {
        "id": "cD6W_IW6Gu8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 15\n",
        "onecycle = OneCycleScheduler(math.ceil(len(X_train_scaled) / batch_size) * n_epochs, max_rate=0.05)\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs, batch_size=batch_size,\n",
        "                    validation_data=(X_valid_scaled, y_val),\n",
        "                    callbacks=[onecycle])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWGonVxeGduX",
        "outputId": "3eeffd90-94e1-471e-bd1f-6f4e826f9291"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "176/176 [==============================] - 4s 14ms/step - loss: 2.1477 - accuracy: 0.2641 - val_loss: 1.7996 - val_accuracy: 0.3630\n",
            "Epoch 2/15\n",
            "176/176 [==============================] - 2s 12ms/step - loss: 1.8517 - accuracy: 0.3544 - val_loss: 1.7234 - val_accuracy: 0.3940\n",
            "Epoch 3/15\n",
            "176/176 [==============================] - 2s 12ms/step - loss: 1.7135 - accuracy: 0.3931 - val_loss: 1.6776 - val_accuracy: 0.4148\n",
            "Epoch 4/15\n",
            "176/176 [==============================] - 2s 12ms/step - loss: 1.6186 - accuracy: 0.4250 - val_loss: 1.6426 - val_accuracy: 0.4246\n",
            "Epoch 5/15\n",
            "176/176 [==============================] - 2s 12ms/step - loss: 1.5517 - accuracy: 0.4479 - val_loss: 1.5981 - val_accuracy: 0.4382\n",
            "Epoch 6/15\n",
            "176/176 [==============================] - 2s 12ms/step - loss: 1.5034 - accuracy: 0.4692 - val_loss: 1.5755 - val_accuracy: 0.4444\n",
            "Epoch 7/15\n",
            "176/176 [==============================] - 2s 12ms/step - loss: 1.4641 - accuracy: 0.4818 - val_loss: 1.5797 - val_accuracy: 0.4528\n",
            "Epoch 8/15\n",
            "176/176 [==============================] - 2s 12ms/step - loss: 1.3952 - accuracy: 0.5058 - val_loss: 1.5514 - val_accuracy: 0.4706\n",
            "Epoch 9/15\n",
            "176/176 [==============================] - 2s 12ms/step - loss: 1.3175 - accuracy: 0.5320 - val_loss: 1.5405 - val_accuracy: 0.4800\n",
            "Epoch 10/15\n",
            "176/176 [==============================] - 2s 12ms/step - loss: 1.2591 - accuracy: 0.5508 - val_loss: 1.5218 - val_accuracy: 0.4826\n",
            "Epoch 11/15\n",
            "176/176 [==============================] - 2s 12ms/step - loss: 1.1943 - accuracy: 0.5778 - val_loss: 1.5406 - val_accuracy: 0.4954\n",
            "Epoch 12/15\n",
            "176/176 [==============================] - 2s 12ms/step - loss: 1.1349 - accuracy: 0.5943 - val_loss: 1.5165 - val_accuracy: 0.4950\n",
            "Epoch 13/15\n",
            "176/176 [==============================] - 5s 28ms/step - loss: 1.0777 - accuracy: 0.6150 - val_loss: 1.5670 - val_accuracy: 0.5068\n",
            "Epoch 14/15\n",
            "176/176 [==============================] - 2s 12ms/step - loss: 1.0282 - accuracy: 0.6360 - val_loss: 1.5620 - val_accuracy: 0.5056\n",
            "Epoch 15/15\n",
            "176/176 [==============================] - 2s 12ms/step - loss: 0.9966 - accuracy: 0.6468 - val_loss: 1.5854 - val_accuracy: 0.5058\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class LayerNormalization(layers.Layer):\n",
        "    def __init__(self, eps=0.001, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.eps = eps\n",
        "    def build(self, input_shape):\n",
        "        self.alpha = self.add_weight(\n",
        "            shape=input_shape[-1:],\n",
        "            name=\"alpha\",\n",
        "            initializer=\"ones\",\n",
        "            dtype=\"float32\",\n",
        "        )\n",
        "        self.beta = self.add_weight(\n",
        "            shape=input_shape[-1:],\n",
        "            name=\"beta\",\n",
        "            initializer=\"zeros\",\n",
        "            dtype=\"float32\",\n",
        "        )\n",
        "        super().build(input_shape)\n",
        "\n",
        "    def call(self, X):\n",
        "      mean, variance = tf.nn.moments(X, axes=-1, keepdims=True)\n",
        "      return self.alpha * (X - mean) / (tf.sqrt(variance + self.eps)) + self.beta\n",
        "\n",
        "    def compute_output_shape(self, batch_input_shape):\n",
        "      return batch_input_shape\n",
        "\n",
        "    def get_config(self):\n",
        "      base_config = super().get_config()\n",
        "      return {**base_config, \"eps\": self.eps}"
      ],
      "metadata": {
        "id": "5DtcbWLxJO1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = X_train.astype(np.float32)\n",
        "\n",
        "custom_layer_norm = LayerNormalization()\n",
        "keras_layer_norm = keras.layers.LayerNormalization()\n",
        "\n",
        "tf.reduce_mean(keras.losses.mean_absolute_error(\n",
        "    keras_layer_norm(X), custom_layer_norm(X)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUHTRYrL9WcK",
        "outputId": "a42bb644-44d6-47ea-b8ec-1afa5df423de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-01-20 04:25:58.910096: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=4.7449034e-06>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_alpha = np.random.rand(X.shape[-1])\n",
        "random_beta = np.random.rand(X.shape[-1])\n",
        "\n",
        "custom_layer_norm.set_weights([random_alpha, random_beta])\n",
        "keras_layer_norm.set_weights([random_alpha, random_beta])\n",
        "\n",
        "tf.reduce_mean(keras.losses.mean_absolute_error(\n",
        "    keras_layer_norm(X), custom_layer_norm(X)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0no7gwjB9cMu",
        "outputId": "8c843b82-2c4d-4ad9-f08d-464e0ca860c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=3.2543217e-06>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D2-6ordg9mSX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}